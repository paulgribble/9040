[
  {
    "objectID": "uv.html",
    "href": "uv.html",
    "title": "uv",
    "section": "",
    "text": "The uv program is a Python package and project manager. It is like pip or virtualenv (sort of like conda) but it is much faster and more modern. We will be using uv in the course to demo code and you will be using uv for your homework assignments.\n\na uv guide: working on projects\nproject concepts in uv"
  },
  {
    "objectID": "uv.html#what-is-uv",
    "href": "uv.html#what-is-uv",
    "title": "uv",
    "section": "",
    "text": "The uv program is a Python package and project manager. It is like pip or virtualenv (sort of like conda) but it is much faster and more modern. We will be using uv in the course to demo code and you will be using uv for your homework assignments.\n\na uv guide: working on projects\nproject concepts in uv"
  },
  {
    "objectID": "plaintext-authoring.html",
    "href": "plaintext-authoring.html",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "What does a thesis or a paper consist of, structurally?\n\nSections and subsections with headings\nBody text (paragraphs of prose)\nEquations (inline and display)\nFigures with captions and cross-references\nTables\nCitations and a bibliography\nMaybe an abstract, appendices, acknowledgements\n\nHow much of that is formatting, and how much is content?\nA scientific document is structured text and data. The formatting, like fonts, margins, and line spacing, is something a template or style can handle. It’s a nuisance and a time-waster to fiddle with that stuff by hand. The principle of separation of content and style is one of the main rationales of plaintext authoring.\n\n\nIn Microsoft Word or Google Docs, content and formatting are entangled. You write a heading by selecting text and making it bold and 14pt. You don’t declare it as a heading in any structural sense (unless you use Styles, which almost nobody does consistently). The file format (.docx) is a zipped bundle of XML that is not human-readable. If Word (or Google) changes how it handles that format, or if you don’t have Word, you may not be able to open your own file in 10 years. If something goes wrong with the document you may not be able to “see” what changed because formatting and other things are hidden within menus and preferences settings.\n\n\n\nIn a plaintext workflow, you write your content in a simple text file, which is something you can open in Notepad, TextEdit, VS Code, or any other text editor on any computer, today or in 50 years. You mark up structure with lightweight, readable syntax (more on this later). Then a separate tool converts that source file into a PDF, HTML page, or even a Word document.\nIn the plaintext authoring model your document is: - portable - archivable - version-controllable - platform-independent\n\n\n\nHere’s the situation:\n\nMany journals accept LaTeX submissions directly. In physics, math, CS, and economics, LaTeX is the expected format. In neuroscience, biology, and psychology, it varies, but many journals do accept LaTeX (e.g., Nature, Nature Neuroscience, Science, PNAS, Cell, Neuron, eLife, J Neurosci, J Cogn Neurosci, all the APA journals, SAGE journals, Elsevier journals, Springer journals).\nPandoc can convert your Markdown or LaTeX source to .docx in one command. You write in plaintext, and when a journal demands Word, you generate a Word file at the end.\nThe real question is: where do you want to spend your time? Formatting in Word, or writing? Chasing down a reference that didn’t update, or trusting BibTeX? Emailing thesis_v3_FINAL_revised_FINAL2.docx back and forth, or using Git?\nYour thesis is long. Word can struggle with documents over ~50 pages that contain many figures and cross-references.\nGoogle Docs solves the collaboration and platform-independence problems nicely, and for short, simple documents it’s fine. But it shares Word’s limitation of entangling content and style, it has very limited equation support, it handles citations through third-party add-ons (Zotero, Paperpile), and try reformatting a 200-page Google Doc to a different journal’s style. You’ll also notice that Google Docs has no real support for cross-references, numbered equations, or figure captions that update automatically.\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nWord / Google Docs\nPlaintext (Markdown / LaTeX)\n\n\n\n\nHuman-readable source\nNo (binary/XML)\nYes\n\n\nVersion control (Git)\nDifficult\nNatural\n\n\nSeparation of content & style\nWeak (manual)\nStrong (by design)\n\n\nEquation support\nCumbersome\nExcellent (LaTeX math)\n\n\nCitation management\nPlugin-dependent\nBuilt-in (BibTeX/CSL)\n\n\nLong document stability\nDegrades\nRobust\n\n\nCollaboration\nGood (Google Docs)\nGit + plain text diffs / Overleaf\n\n\nOutput flexibility\nOne format\nPDF, HTML, Word, slides, …\n\n\nArchival / portability\nFormat-dependent\nPlain text lasts forever\n\n\nTypographic quality\nAcceptable\nSuperior (LaTeX)\n\n\n\n\n\n\n\n\nMarkdown is a lightweight markup language created by John Gruber in 2004. It was designed to be readable as-is. The idea is that you shouldn’t need to “compile” it to understand what the author meant.\n\n\nHere is what a Markdown document looks like:\n# My Research Paper\n\n## Introduction\n\nThis is a paragraph of text. You can make words **bold** or *italic*.\nYou can also include `inline code` for variable names or filenames.\n\nHere is a list of things:\n\n- First item\n- Second item\n- Third item\n\nAnd a numbered list:\n\n1. Do the experiment\n2. Analyze the data\n3. Write it up\n\n## Methods\n\nWe recruited 24 participants (12 female, mean age = 22.3 years).\nStimuli were presented using PsychoPy [@peirce2019psychopy].\n\n### Apparatus\n\nThe display was a 24-inch monitor at 60 Hz.\n\n## Results\n\nReaction times are shown in Table 1 and Figure 1.\nThat’s it. It’s just text with some punctuation conventions.\n\n\n\n\n\n\nElement\nSyntax\nRenders as\n\n\n\n\nHeading 1\n# Title\nLarge heading\n\n\nHeading 2\n## Section\nSection heading\n\n\nHeading 3\n### Subsection\nSubsection heading\n\n\nBold\n**bold**\nbold\n\n\nItalic\n*italic*\nitalic\n\n\nInline code\n`code`\ncode\n\n\nLink\n[text](url)\nclickable link\n\n\nImage\n![caption](path.png)\nembedded image\n\n\nBlockquote\n&gt; quoted text\nindented quote\n\n\nHorizontal rule\n---\ndivider line\n\n\n\n\n\n\nPandoc (which we’ll meet next) extends basic Markdown with features essential for academic writing:\n\nCitations: [@smith2020] or @smith2020\nFootnotes: ^[This is a footnote.]\nMath: $E = mc^2$ for inline, $$\\sum_{i=1}^n x_i$$ for display\nFigure captions: ![Caption text](figure.png){width=80%}\nTables with captions\nCross-references (with filters like pandoc-crossref)\nYAML metadata blocks for title, author, date, and formatting options\n\n\n\n\n\nMarkdown basics: https://www.markdownguide.org/basic-syntax/\nPandoc’s Markdown extensions: https://pandoc.org/MANUAL.html#pandocs-markdown\nPractice: https://www.markdowntutorial.com/ (interactive, takes ~15 minutes)\n\n\n\n\n\n\nPandoc is a command-line tool created by Professor or Philosophy (and programmer) John MacFarlane. It converts between dozens of document formats, e.g.:\nMarkdown → PDF, Word, HTML, LaTeX (and back)\n\n\n\nmacOS: brew install pandoc (via Homebrew) or download from https://pandoc.org/installing.html\nWindows (WSL/Ubuntu): sudo apt install pandoc\nOr download the latest release directly: https://github.com/jgc/pandoc/releases → actually: https://github.com/jgc/pandoc/releases — use https://pandoc.org/installing.html\n\nYou also need a LaTeX distribution for PDF output (Pandoc uses LaTeX under the hood to make PDFs):\n\nmacOS: brew install --cask mactex or the smaller brew install --cask basictex\nWSL/Ubuntu: sudo apt install texlive-full (large, ~5 GB) or sudo apt install texlive-latex-recommended texlive-fonts-recommended texlive-latex-extra (smaller)\n\nA lightweight alternative to a full LaTeX install is Tectonic, which auto-downloads only the packages it needs.\n\n\n\n# Markdown to PDF\npandoc paper.md -o paper.pdf\n\n# Markdown to Word\npandoc paper.md -o paper.docx\n\n# Markdown to HTML\npandoc paper.md -o paper.html\n\n# Markdown to LaTeX (to inspect or edit the .tex source)\npandoc paper.md -o paper.tex\nPandoc infers the output format from the file extension.\n\n\n\nAt the top of your Markdown file, you can add a YAML metadata block:\n---\ntitle: \"Reaction Time Effects of Sleep Deprivation\"\nauthor: \"Jane Smith\"\ndate: \"2025-01-15\"\nabstract: |\n  We investigated the effects of 24 hours of sleep deprivation\n  on simple and choice reaction times in 48 participants ...\nbibliography: references.bib\ncsl: apa.csl\ngeometry: margin=1in\nfontsize: 12pt\n---\nThis tells Pandoc the title, author, which bibliography file to use, which citation style (CSL) to apply, and basic page geometry — all without touching a GUI.\n\n\n\nPandoc uses a .bib file (BibTeX format) for references. You can export .bib files from Zotero, Mendeley, Google Scholar, or write them by hand.\nA .bib entry looks like this:\n@article{smith2020sleep,\n  author  = {Smith, Jane and Doe, John},\n  title   = {Sleep deprivation and reaction time},\n  journal = {Journal of Sleep Research},\n  year    = {2020},\n  volume  = {29},\n  pages   = {e13045},\n  doi     = {10.1111/jsr.13045}\n}\nIn your Markdown, you cite it as [@smith2020sleep], and Pandoc replaces that with a formatted citation (e.g., “(Smith & Doe, 2020)”) and generates the bibliography automatically.\nTo compile with citations:\npandoc paper.md --citeproc -o paper.pdf\nThe --citeproc flag tells Pandoc to process citations. The citation style is controlled by the csl: field in your YAML header. You can download thousands of CSL styles from https://www.zotero.org/styles (APA, Vancouver, Harvard, Nature, IEEE, etc.).\n\n\n\n\nPandoc user’s guide: https://pandoc.org/MANUAL.html\nPandoc getting started: https://pandoc.org/getting-started.html\nCitation Style Language styles: https://www.zotero.org/styles\nBibTeX entry types: https://www.bibtex.com/e/entry-types/\n\n\n\n\n\n\n\n\nMake sure you have Pandoc and a LaTeX distribution installed (see above).\nDownload the files/plaintext-exercises.tgz archive, move it to your Psych_9040/ directory, and then unpack it:\n$ tar -xvzf plaintext-exercises.tgz\nThis is what it looks like:\n$ tree -F plaintext-exercises\nplaintext-exercises/\n├── exercise1/\n│   ├── exercise1.md\n│   ├── refs.bib\n│   └── TASKS.md\n├── exercise2/\n│   ├── exercise2.tex\n│   ├── refs.bib\n│   ├── sample_figure.pdf\n│   ├── sample_figure.png\n│   └── TASKS.md\n├── exercise3/\n│   ├── exercise3.md\n│   ├── refs.bib\n│   ├── search_figure.pdf\n│   ├── search_figure.png\n│   └── TASKS.md\n├── README.md\n└── setup.sh\nNow run the setup.sh script which downloads a .csl file that will be used for APA-style citations:\n$ bash setup.sh\nDownloading APA 7th edition citation style...\nCopying apa.csl into exercise folders...\n  → exercise1/apa.csl\n  → exercise2/apa.csl\n  → exercise3/apa.csl\n\nDone! You're ready for the exercises.\nFor this exercise we will be using the files in the exercise1/ directory:\n\n\n\nYou are given a starter file exercise1.md (see below). Your tasks:\n\nRead the file in a text editor. Notice how readable it is even as raw text.\nCompile it to PDF: pandoc exercise1.md --citeproc -o exercise1.pdf\nCompile it to Word: pandoc exercise1.md --citeproc -o exercise1.docx\nOpen both outputs. Compare them to the source.\nAdd the following to the document:\n\nA new subsection under Methods called ### Data Analysis\nA sentence describing the analysis, citing a new reference (add it to the .bib file)\nAn inline equation: the formula for a t-statistic, t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}}\nRecompile to PDF and verify your additions appear correctly.\n\n\nHint: writing equations in LaTeX can be strange at first, they have a syntax/grammar all their own, but once you get the hang of it, it’s actually pretty easy and very efficient. Here is some documentation: LaTeX Mathematics.\n\n\n\n---\ntitle: \"Effects of Caffeine on Grip Strength\"\nauthor: \"A. Student\"\ndate: \"2025-02-01\"\nbibliography: refs.bib\ncsl: apa.csl\ngeometry: margin=1in\nfontsize: 12pt\n---\n\n# Introduction\n\nCaffeine is the most widely consumed psychoactive substance in the\nworld [@fredholm1999actions]. Its effects on cognitive performance\nare well-documented, but effects on motor performance are less clear.\n\n# Methods\n\n## Participants\n\nWe recruited 30 healthy adults (15 female, mean age = 23.1 years,\nSD = 3.4) from the university community.\n\n## Procedure\n\nParticipants completed a maximal grip strength test using a hand\ndynamometer before and 45 minutes after consuming either 200 mg\ncaffeine or placebo in a double-blind design.\n\n# Results\n\nMean grip strength increased by 2.3 N (SD = 4.1) in the caffeine\ncondition and 0.4 N (SD = 3.8) in the placebo condition.\n\n# Discussion\n\nThese preliminary results suggest a small positive effect of caffeine\non grip strength, consistent with @warren2010effect.\n\n# References\n\n\n\n@article{fredholm1999actions,\n  author  = {Fredholm, Bertil B and Bättig, Karl and Holmén, Janet\n             and Nehlig, Astrid and Zvartau, Edwin E},\n  title   = {Actions of caffeine in the brain with special reference\n             to factors that contribute to its widespread use},\n  journal = {Pharmacological Reviews},\n  year    = {1999},\n  volume  = {51},\n  number  = {1},\n  pages   = {83--133}\n}\n\n@article{warren2010effect,\n  author  = {Warren, Gregory L and Park, Nicole D and Maresca,\n             Robert D and McKibans, Kimberly I and Millard-Stafford,\n             Mindy L},\n  title   = {Effect of caffeine ingestion on muscular strength and\n             endurance},\n  journal = {Medicine and Science in Sports and Exercise},\n  year    = {2010},\n  volume  = {42},\n  number  = {7},\n  pages   = {1375--1387}\n}\n\n\n\n\nHow does the PDF compare to the Word output?\nHow easy is it to add a citation compared to using a Word plugin?\nWhat happens when you make a typo in the citation key?\n\n\n\n\n\n\nToday we learned:\n\nWhy plaintext is a compelling choice for scientific writing\nThe basics of Markdown syntax\nHow Pandoc converts Markdown to PDF, Word, and other formats\nHow to handle citations with BibTeX and CSL\n\nIn the next section we will dive into LaTeX, which is the typesetting system that pandoc uses under the hood. We will look at how to write LaTeX directly (useful for when you need fine-grained control), how to handle equations, figures, tables, and cross-references, and how to use Overleaf for collaborative LaTeX editing. Many people write LaTeX directly, bypassing Markdown and Pandoc altogether. Historical note: I wrote my very first journal article in LaTeX back in 1994, and today it is still viewable, editable, and compiles to pdf, using free and open source tools.\nFor next time:\n\nVerify that your LaTeX distribution is working: try pdflatex --version in your terminal.\nCreate a free account on Overleaf, we will use it for an exercise.\n(Optional) Work through the interactive Markdown tutorial: https://www.markdowntutorial.com/"
  },
  {
    "objectID": "plaintext-authoring.html#what-is-a-scientific-document",
    "href": "plaintext-authoring.html#what-is-a-scientific-document",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "What does a thesis or a paper consist of, structurally?\n\nSections and subsections with headings\nBody text (paragraphs of prose)\nEquations (inline and display)\nFigures with captions and cross-references\nTables\nCitations and a bibliography\nMaybe an abstract, appendices, acknowledgements\n\nHow much of that is formatting, and how much is content?\nA scientific document is structured text and data. The formatting, like fonts, margins, and line spacing, is something a template or style can handle. It’s a nuisance and a time-waster to fiddle with that stuff by hand. The principle of separation of content and style is one of the main rationales of plaintext authoring.\n\n\nIn Microsoft Word or Google Docs, content and formatting are entangled. You write a heading by selecting text and making it bold and 14pt. You don’t declare it as a heading in any structural sense (unless you use Styles, which almost nobody does consistently). The file format (.docx) is a zipped bundle of XML that is not human-readable. If Word (or Google) changes how it handles that format, or if you don’t have Word, you may not be able to open your own file in 10 years. If something goes wrong with the document you may not be able to “see” what changed because formatting and other things are hidden within menus and preferences settings.\n\n\n\nIn a plaintext workflow, you write your content in a simple text file, which is something you can open in Notepad, TextEdit, VS Code, or any other text editor on any computer, today or in 50 years. You mark up structure with lightweight, readable syntax (more on this later). Then a separate tool converts that source file into a PDF, HTML page, or even a Word document.\nIn the plaintext authoring model your document is: - portable - archivable - version-controllable - platform-independent\n\n\n\nHere’s the situation:\n\nMany journals accept LaTeX submissions directly. In physics, math, CS, and economics, LaTeX is the expected format. In neuroscience, biology, and psychology, it varies, but many journals do accept LaTeX (e.g., Nature, Nature Neuroscience, Science, PNAS, Cell, Neuron, eLife, J Neurosci, J Cogn Neurosci, all the APA journals, SAGE journals, Elsevier journals, Springer journals).\nPandoc can convert your Markdown or LaTeX source to .docx in one command. You write in plaintext, and when a journal demands Word, you generate a Word file at the end.\nThe real question is: where do you want to spend your time? Formatting in Word, or writing? Chasing down a reference that didn’t update, or trusting BibTeX? Emailing thesis_v3_FINAL_revised_FINAL2.docx back and forth, or using Git?\nYour thesis is long. Word can struggle with documents over ~50 pages that contain many figures and cross-references.\nGoogle Docs solves the collaboration and platform-independence problems nicely, and for short, simple documents it’s fine. But it shares Word’s limitation of entangling content and style, it has very limited equation support, it handles citations through third-party add-ons (Zotero, Paperpile), and try reformatting a 200-page Google Doc to a different journal’s style. You’ll also notice that Google Docs has no real support for cross-references, numbered equations, or figure captions that update automatically.\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nWord / Google Docs\nPlaintext (Markdown / LaTeX)\n\n\n\n\nHuman-readable source\nNo (binary/XML)\nYes\n\n\nVersion control (Git)\nDifficult\nNatural\n\n\nSeparation of content & style\nWeak (manual)\nStrong (by design)\n\n\nEquation support\nCumbersome\nExcellent (LaTeX math)\n\n\nCitation management\nPlugin-dependent\nBuilt-in (BibTeX/CSL)\n\n\nLong document stability\nDegrades\nRobust\n\n\nCollaboration\nGood (Google Docs)\nGit + plain text diffs / Overleaf\n\n\nOutput flexibility\nOne format\nPDF, HTML, Word, slides, …\n\n\nArchival / portability\nFormat-dependent\nPlain text lasts forever\n\n\nTypographic quality\nAcceptable\nSuperior (LaTeX)"
  },
  {
    "objectID": "plaintext-authoring.html#markdown-the-simplest-plaintext-markup",
    "href": "plaintext-authoring.html#markdown-the-simplest-plaintext-markup",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "Markdown is a lightweight markup language created by John Gruber in 2004. It was designed to be readable as-is. The idea is that you shouldn’t need to “compile” it to understand what the author meant.\n\n\nHere is what a Markdown document looks like:\n# My Research Paper\n\n## Introduction\n\nThis is a paragraph of text. You can make words **bold** or *italic*.\nYou can also include `inline code` for variable names or filenames.\n\nHere is a list of things:\n\n- First item\n- Second item\n- Third item\n\nAnd a numbered list:\n\n1. Do the experiment\n2. Analyze the data\n3. Write it up\n\n## Methods\n\nWe recruited 24 participants (12 female, mean age = 22.3 years).\nStimuli were presented using PsychoPy [@peirce2019psychopy].\n\n### Apparatus\n\nThe display was a 24-inch monitor at 60 Hz.\n\n## Results\n\nReaction times are shown in Table 1 and Figure 1.\nThat’s it. It’s just text with some punctuation conventions.\n\n\n\n\n\n\nElement\nSyntax\nRenders as\n\n\n\n\nHeading 1\n# Title\nLarge heading\n\n\nHeading 2\n## Section\nSection heading\n\n\nHeading 3\n### Subsection\nSubsection heading\n\n\nBold\n**bold**\nbold\n\n\nItalic\n*italic*\nitalic\n\n\nInline code\n`code`\ncode\n\n\nLink\n[text](url)\nclickable link\n\n\nImage\n![caption](path.png)\nembedded image\n\n\nBlockquote\n&gt; quoted text\nindented quote\n\n\nHorizontal rule\n---\ndivider line\n\n\n\n\n\n\nPandoc (which we’ll meet next) extends basic Markdown with features essential for academic writing:\n\nCitations: [@smith2020] or @smith2020\nFootnotes: ^[This is a footnote.]\nMath: $E = mc^2$ for inline, $$\\sum_{i=1}^n x_i$$ for display\nFigure captions: ![Caption text](figure.png){width=80%}\nTables with captions\nCross-references (with filters like pandoc-crossref)\nYAML metadata blocks for title, author, date, and formatting options\n\n\n\n\n\nMarkdown basics: https://www.markdownguide.org/basic-syntax/\nPandoc’s Markdown extensions: https://pandoc.org/MANUAL.html#pandocs-markdown\nPractice: https://www.markdowntutorial.com/ (interactive, takes ~15 minutes)"
  },
  {
    "objectID": "plaintext-authoring.html#pandoc-the-universal-document-converter",
    "href": "plaintext-authoring.html#pandoc-the-universal-document-converter",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "Pandoc is a command-line tool created by Professor or Philosophy (and programmer) John MacFarlane. It converts between dozens of document formats, e.g.:\nMarkdown → PDF, Word, HTML, LaTeX (and back)\n\n\n\nmacOS: brew install pandoc (via Homebrew) or download from https://pandoc.org/installing.html\nWindows (WSL/Ubuntu): sudo apt install pandoc\nOr download the latest release directly: https://github.com/jgc/pandoc/releases → actually: https://github.com/jgc/pandoc/releases — use https://pandoc.org/installing.html\n\nYou also need a LaTeX distribution for PDF output (Pandoc uses LaTeX under the hood to make PDFs):\n\nmacOS: brew install --cask mactex or the smaller brew install --cask basictex\nWSL/Ubuntu: sudo apt install texlive-full (large, ~5 GB) or sudo apt install texlive-latex-recommended texlive-fonts-recommended texlive-latex-extra (smaller)\n\nA lightweight alternative to a full LaTeX install is Tectonic, which auto-downloads only the packages it needs.\n\n\n\n# Markdown to PDF\npandoc paper.md -o paper.pdf\n\n# Markdown to Word\npandoc paper.md -o paper.docx\n\n# Markdown to HTML\npandoc paper.md -o paper.html\n\n# Markdown to LaTeX (to inspect or edit the .tex source)\npandoc paper.md -o paper.tex\nPandoc infers the output format from the file extension.\n\n\n\nAt the top of your Markdown file, you can add a YAML metadata block:\n---\ntitle: \"Reaction Time Effects of Sleep Deprivation\"\nauthor: \"Jane Smith\"\ndate: \"2025-01-15\"\nabstract: |\n  We investigated the effects of 24 hours of sleep deprivation\n  on simple and choice reaction times in 48 participants ...\nbibliography: references.bib\ncsl: apa.csl\ngeometry: margin=1in\nfontsize: 12pt\n---\nThis tells Pandoc the title, author, which bibliography file to use, which citation style (CSL) to apply, and basic page geometry — all without touching a GUI.\n\n\n\nPandoc uses a .bib file (BibTeX format) for references. You can export .bib files from Zotero, Mendeley, Google Scholar, or write them by hand.\nA .bib entry looks like this:\n@article{smith2020sleep,\n  author  = {Smith, Jane and Doe, John},\n  title   = {Sleep deprivation and reaction time},\n  journal = {Journal of Sleep Research},\n  year    = {2020},\n  volume  = {29},\n  pages   = {e13045},\n  doi     = {10.1111/jsr.13045}\n}\nIn your Markdown, you cite it as [@smith2020sleep], and Pandoc replaces that with a formatted citation (e.g., “(Smith & Doe, 2020)”) and generates the bibliography automatically.\nTo compile with citations:\npandoc paper.md --citeproc -o paper.pdf\nThe --citeproc flag tells Pandoc to process citations. The citation style is controlled by the csl: field in your YAML header. You can download thousands of CSL styles from https://www.zotero.org/styles (APA, Vancouver, Harvard, Nature, IEEE, etc.).\n\n\n\n\nPandoc user’s guide: https://pandoc.org/MANUAL.html\nPandoc getting started: https://pandoc.org/getting-started.html\nCitation Style Language styles: https://www.zotero.org/styles\nBibTeX entry types: https://www.bibtex.com/e/entry-types/"
  },
  {
    "objectID": "plaintext-authoring.html#exercise-1-your-first-pandoc-markdown-document",
    "href": "plaintext-authoring.html#exercise-1-your-first-pandoc-markdown-document",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "Make sure you have Pandoc and a LaTeX distribution installed (see above).\nDownload the files/plaintext-exercises.tgz archive, move it to your Psych_9040/ directory, and then unpack it:\n$ tar -xvzf plaintext-exercises.tgz\nThis is what it looks like:\n$ tree -F plaintext-exercises\nplaintext-exercises/\n├── exercise1/\n│   ├── exercise1.md\n│   ├── refs.bib\n│   └── TASKS.md\n├── exercise2/\n│   ├── exercise2.tex\n│   ├── refs.bib\n│   ├── sample_figure.pdf\n│   ├── sample_figure.png\n│   └── TASKS.md\n├── exercise3/\n│   ├── exercise3.md\n│   ├── refs.bib\n│   ├── search_figure.pdf\n│   ├── search_figure.png\n│   └── TASKS.md\n├── README.md\n└── setup.sh\nNow run the setup.sh script which downloads a .csl file that will be used for APA-style citations:\n$ bash setup.sh\nDownloading APA 7th edition citation style...\nCopying apa.csl into exercise folders...\n  → exercise1/apa.csl\n  → exercise2/apa.csl\n  → exercise3/apa.csl\n\nDone! You're ready for the exercises.\nFor this exercise we will be using the files in the exercise1/ directory:\n\n\n\nYou are given a starter file exercise1.md (see below). Your tasks:\n\nRead the file in a text editor. Notice how readable it is even as raw text.\nCompile it to PDF: pandoc exercise1.md --citeproc -o exercise1.pdf\nCompile it to Word: pandoc exercise1.md --citeproc -o exercise1.docx\nOpen both outputs. Compare them to the source.\nAdd the following to the document:\n\nA new subsection under Methods called ### Data Analysis\nA sentence describing the analysis, citing a new reference (add it to the .bib file)\nAn inline equation: the formula for a t-statistic, t = \\frac{\\bar{X} - \\mu}{s / \\sqrt{n}}\nRecompile to PDF and verify your additions appear correctly.\n\n\nHint: writing equations in LaTeX can be strange at first, they have a syntax/grammar all their own, but once you get the hang of it, it’s actually pretty easy and very efficient. Here is some documentation: LaTeX Mathematics.\n\n\n\n---\ntitle: \"Effects of Caffeine on Grip Strength\"\nauthor: \"A. Student\"\ndate: \"2025-02-01\"\nbibliography: refs.bib\ncsl: apa.csl\ngeometry: margin=1in\nfontsize: 12pt\n---\n\n# Introduction\n\nCaffeine is the most widely consumed psychoactive substance in the\nworld [@fredholm1999actions]. Its effects on cognitive performance\nare well-documented, but effects on motor performance are less clear.\n\n# Methods\n\n## Participants\n\nWe recruited 30 healthy adults (15 female, mean age = 23.1 years,\nSD = 3.4) from the university community.\n\n## Procedure\n\nParticipants completed a maximal grip strength test using a hand\ndynamometer before and 45 minutes after consuming either 200 mg\ncaffeine or placebo in a double-blind design.\n\n# Results\n\nMean grip strength increased by 2.3 N (SD = 4.1) in the caffeine\ncondition and 0.4 N (SD = 3.8) in the placebo condition.\n\n# Discussion\n\nThese preliminary results suggest a small positive effect of caffeine\non grip strength, consistent with @warren2010effect.\n\n# References\n\n\n\n@article{fredholm1999actions,\n  author  = {Fredholm, Bertil B and Bättig, Karl and Holmén, Janet\n             and Nehlig, Astrid and Zvartau, Edwin E},\n  title   = {Actions of caffeine in the brain with special reference\n             to factors that contribute to its widespread use},\n  journal = {Pharmacological Reviews},\n  year    = {1999},\n  volume  = {51},\n  number  = {1},\n  pages   = {83--133}\n}\n\n@article{warren2010effect,\n  author  = {Warren, Gregory L and Park, Nicole D and Maresca,\n             Robert D and McKibans, Kimberly I and Millard-Stafford,\n             Mindy L},\n  title   = {Effect of caffeine ingestion on muscular strength and\n             endurance},\n  journal = {Medicine and Science in Sports and Exercise},\n  year    = {2010},\n  volume  = {42},\n  number  = {7},\n  pages   = {1375--1387}\n}\n\n\n\n\nHow does the PDF compare to the Word output?\nHow easy is it to add a citation compared to using a Word plugin?\nWhat happens when you make a typo in the citation key?"
  },
  {
    "objectID": "plaintext-authoring.html#summary",
    "href": "plaintext-authoring.html#summary",
    "title": "Plaintext Authoring",
    "section": "",
    "text": "Today we learned:\n\nWhy plaintext is a compelling choice for scientific writing\nThe basics of Markdown syntax\nHow Pandoc converts Markdown to PDF, Word, and other formats\nHow to handle citations with BibTeX and CSL\n\nIn the next section we will dive into LaTeX, which is the typesetting system that pandoc uses under the hood. We will look at how to write LaTeX directly (useful for when you need fine-grained control), how to handle equations, figures, tables, and cross-references, and how to use Overleaf for collaborative LaTeX editing. Many people write LaTeX directly, bypassing Markdown and Pandoc altogether. Historical note: I wrote my very first journal article in LaTeX back in 1994, and today it is still viewable, editable, and compiles to pdf, using free and open source tools.\nFor next time:\n\nVerify that your LaTeX distribution is working: try pdflatex --version in your terminal.\nCreate a free account on Overleaf, we will use it for an exercise.\n(Optional) Work through the interactive Markdown tutorial: https://www.markdowntutorial.com/"
  },
  {
    "objectID": "plaintext-authoring.html#what-is-latex-and-why-does-it-exist-8-min",
    "href": "plaintext-authoring.html#what-is-latex-and-why-does-it-exist-8-min",
    "title": "Plaintext Authoring",
    "section": "2.1 — What Is LaTeX and Why Does It Exist? (8 min)",
    "text": "2.1 — What Is LaTeX and Why Does It Exist? (8 min)\nLaTeX (pronounced “LAH-tek” or “LAY-tek”) is a typesetting system created by Leslie Lamport in 1984, built on top of Donald Knuth’s TeX (1978). Knuth, a computer scientist, created TeX because he was unhappy with the typographic quality of his textbooks. LaTeX adds a layer of convenience on top of TeX.\nWhen you compile a LaTeX document, the system makes thousands of micro-decisions about line breaks, hyphenation, spacing, and page layout. The result is typographically excellent output — the kind of polished, professional look you see in textbooks and journal articles.\n\nHow Markdown + Pandoc Relates to LaTeX\nWhen you ran pandoc paper.md -o paper.pdf in Lecture 1, Pandoc actually:\n\nConverted your Markdown to LaTeX behind the scenes\nCalled pdflatex (or xelatex) to compile the LaTeX to PDF\n\nSo you’ve already been using LaTeX — you just had Pandoc as a middleman. Learning LaTeX directly gives you much finer control when you need it.\n\n\nWhen to Use Markdown+Pandoc vs. LaTeX Directly\n\n\n\n\n\n\n\nScenario\nRecommendation\n\n\n\n\nShort paper, simple structure\nMarkdown + Pandoc\n\n\nBlog post, course notes, README\nMarkdown + Pandoc\n\n\nThesis or dissertation\nLaTeX directly (or Markdown for drafting, LaTeX for final)\n\n\nPaper with complex equations\nLaTeX directly\n\n\nPaper with precise figure placement\nLaTeX directly\n\n\nJournal provides a LaTeX template\nLaTeX directly\n\n\nNeed Word output for a journal\nMarkdown + Pandoc (convert to .docx)\n\n\nQuick first draft\nMarkdown + Pandoc\n\n\n\nMany working scientists use a hybrid: draft quickly in Markdown, then move to LaTeX when the document matures and needs fine-tuning."
  },
  {
    "objectID": "plaintext-authoring.html#latex-document-structure-10-min",
    "href": "plaintext-authoring.html#latex-document-structure-10-min",
    "title": "Plaintext Authoring",
    "section": "2.2 — LaTeX Document Structure (10 min)",
    "text": "2.2 — LaTeX Document Structure (10 min)\nA LaTeX document has two parts: the preamble (setup and configuration) and the document body (your content).\n\nMinimal Example\n\\documentclass[12pt]{article}\n\n% --- Preamble: load packages and configure ---\n\\usepackage[margin=1in]{geometry}\n\\usepackage{amsmath}          % better equation support\n\\usepackage{graphicx}         % for including figures\n\\usepackage{booktabs}         % for professional tables\n\\usepackage[\n  backend=biber,\n  style=apa,\n  natbib=true\n]{biblatex}                   % citation management\n\\addbibresource{refs.bib}\n\n\\title{Effects of Caffeine on Grip Strength}\n\\author{A.\\ Student}\n\\date{February 2025}\n\n% --- Document body ---\n\\begin{document}\n\\maketitle\n\n\\begin{abstract}\nWe investigated the effect of 200\\,mg caffeine on maximal\ngrip strength in a double-blind placebo-controlled design.\n\\end{abstract}\n\n\\section{Introduction}\n\nCaffeine is the most widely consumed psychoactive substance\nin the world \\citep{fredholm1999actions}. Its effects on\ncognitive performance are well-documented, but effects on\nmotor performance are less clear.\n\n\\section{Methods}\n\n\\subsection{Participants}\n\nWe recruited 30 healthy adults (15 female, mean age = 23.1\nyears, SD = 3.4) from the university community.\n\n\\subsection{Procedure}\n\nParticipants completed a maximal grip strength test before\nand 45 minutes after consuming caffeine or placebo.\n\n\\section{Results}\n\nThe results are presented in Table~\\ref{tab:results} and\nFigure~\\ref{fig:grip}.\n\n\\section{Discussion}\n\nThese preliminary results suggest a small positive effect\nof caffeine on grip strength \\citep{warren2010effect}.\n\n\\printbibliography\n\n\\end{document}\n\n\nKey Concepts\nCommands start with a backslash: \\section{...}, \\textbf{...}, \\citep{...}\nEnvironments are blocks delimited by \\begin{...} and \\end{...}: \\begin{abstract}...\\end{abstract}, \\begin{figure}...\\end{figure}\nPackages extend LaTeX’s capabilities. You load them in the preamble with \\usepackage{...}. Think of them like Python libraries.\nComments start with % and are ignored by the compiler.\n\n\nCompiling\n# Basic compilation\npdflatex paper.tex\n\n# With bibliography (requires multiple passes)\npdflatex paper.tex\nbiber paper\npdflatex paper.tex\npdflatex paper.tex\n\n# Or use latexmk, which automates the multiple passes:\nlatexmk -pdf paper.tex\nThe multiple passes are needed because LaTeX resolves cross-references and citations iteratively. latexmk handles this automatically and is the recommended way to compile."
  },
  {
    "objectID": "plaintext-authoring.html#equations-8-min",
    "href": "plaintext-authoring.html#equations-8-min",
    "title": "Plaintext Authoring",
    "section": "2.3 — Equations (8 min)",
    "text": "2.3 — Equations (8 min)\nThis is where LaTeX truly shines. The equation syntax is the same whether you’re writing in LaTeX or in Markdown+Pandoc (because Pandoc passes math through to LaTeX).\n\nInline Math\nSurround with single dollar signs:\nThe sample mean is $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$.\n\n\nDisplay Math (Numbered)\nUse the equation environment:\n\\begin{equation}\n  t = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}}\n  \\label{eq:ttest}\n\\end{equation}\nYou can then refer to it with Equation~\\ref{eq:ttest}.\n\n\nDisplay Math (Unnumbered)\n\\[\n  \\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\n\n\nAligned Multi-Line Equations\n\\begin{align}\n  \\text{SS}_{\\text{total}} &= \\text{SS}_{\\text{between}}\n                              + \\text{SS}_{\\text{within}} \\\\\n  F &= \\frac{\\text{MS}_{\\text{between}}}\n             {\\text{MS}_{\\text{within}}}\n\\end{align}\n\n\nCommon Symbols Quick Reference\n\n\n\nWhat you want\nLaTeX code\nRenders as\n\n\n\n\nGreek letters\n\\alpha, \\beta, \\mu, \\sigma\nα, β, μ, σ\n\n\nSubscript\nx_{i}\nxᵢ\n\n\nSuperscript\nx^{2}\nx²\n\n\nFraction\n\\frac{a}{b}\na/b (stacked)\n\n\nSquare root\n\\sqrt{n}\n√n\n\n\nSum\n\\sum_{i=1}^{n}\nΣ\n\n\nIntegral\n\\int_{0}^{\\infty}\n∫\n\n\nHat/bar\n\\hat{\\beta}, \\bar{x}\nβ̂, x̄\n\n\nApproximately\n\\approx\n≈\n\n\nLess/greater or equal\n\\leq, \\geq\n≤, ≥\n\n\nPartial derivative\n\\frac{\\partial f}{\\partial x}\n∂f/∂x\n\n\n\n\n\nResources\n\nDetexify — draw a symbol and it tells you the LaTeX code: https://detexify.kirelabs.org/\nLaTeX math cheat sheet: https://katex.org/docs/supported\nThe amsmath package documentation covers everything: search “amsmath documentation CTAN”"
  },
  {
    "objectID": "plaintext-authoring.html#figures-and-tables-8-min",
    "href": "plaintext-authoring.html#figures-and-tables-8-min",
    "title": "Plaintext Authoring",
    "section": "2.4 — Figures and Tables (8 min)",
    "text": "2.4 — Figures and Tables (8 min)\n\nFigures\n\\begin{figure}[htbp]\n  \\centering\n  \\includegraphics[width=0.8\\textwidth]{figures/grip_strength.pdf}\n  \\caption{Mean grip strength (N) by condition. Error bars show\n           $\\pm 1$ SE.}\n  \\label{fig:grip}\n\\end{figure}\nKey points:\n\n[htbp] = placement preference: here, top of page, bottom, separate page. LaTeX decides the best placement. (This is a feature, not a bug — LaTeX optimizes page layout globally.)\nUse PDF or PNG for figures. PDF is preferred for vector graphics (plots), PNG for raster images (photos, microscopy).\nReference with Figure~\\ref{fig:grip} — the number updates automatically.\nThe tilde ~ prevents a line break between “Figure” and the number.\n\n\n\nTables\n\\begin{table}[htbp]\n  \\centering\n  \\caption{Mean grip strength (N) by condition and time point.}\n  \\label{tab:results}\n  \\begin{tabular}{lcc}\n    \\toprule\n    Condition & Pre & Post \\\\\n    \\midrule\n    Caffeine  & 38.2 (5.1) & 40.5 (5.3) \\\\\n    Placebo   & 37.9 (4.8) & 38.3 (5.0) \\\\\n    \\bottomrule\n  \\end{tabular}\n\\end{table}\nKey points:\n\n{lcc} = three columns: left-aligned, center, center.\n\\toprule, \\midrule, \\bottomrule come from the booktabs package and produce clean, professional horizontal rules (no vertical lines — this is a typographic best practice).\nReference with Table~\\ref{tab:results}.\n\n\n\nTables in Markdown+Pandoc\nPandoc Markdown tables are simpler but less flexible:\n| Condition | Pre        | Post       |\n|-----------|------------|------------|\n| Caffeine  | 38.2 (5.1) | 40.5 (5.3) |\n| Placebo   | 37.9 (4.8) | 38.3 (5.0) |\n\n: Mean grip strength (N) by condition and time point. {#tbl:results}"
  },
  {
    "objectID": "plaintext-authoring.html#breakout-exercise-2-building-a-latex-document-15-min",
    "href": "plaintext-authoring.html#breakout-exercise-2-building-a-latex-document-15-min",
    "title": "Plaintext Authoring",
    "section": "2.5 — Breakout Exercise 2: Building a LaTeX Document (15 min)",
    "text": "2.5 — Breakout Exercise 2: Building a LaTeX Document (15 min)\n\nOption A: Using Overleaf (Recommended for First-Timers)\n\nGo to https://www.overleaf.com/ and log in.\nCreate a new blank project.\nStart with the minimal template from Section 2.2 above.\nComplete these tasks:\n\nTask 1 — Equations: Add a “Data Analysis” subsection under Methods. Include the formula for Pearson’s correlation coefficient as a numbered equation:\nr = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\sum_{i=1}^n (y_i - \\bar{y})^2}}\nThen reference it in the text (“… as shown in Equation 1”).\nTask 2 — Table: Add a Results table with three columns (Measure, Caffeine, Placebo) and at least two rows. Use booktabs rules. Add a caption and label, and reference the table in the text.\nTask 3 — Figure: Download any plot image (or use a placeholder) and include it as a figure with a caption. Reference it in the text. (On Overleaf, use the upload button to add an image file.)\nTask 4 — Citation: Add a new entry to refs.bib and cite it somewhere in the text. Verify it appears in the bibliography.\n\n\nOption B: Local Compilation\nSame tasks, but compile locally:\nlatexmk -pdf paper.tex\nIf you don’t have latexmk, use:\npdflatex paper.tex && biber paper && pdflatex paper.tex && pdflatex paper.tex\n\n\nDebrief\nAfter the exercise, discuss:\n\nHow did the equation-writing experience compare to Word’s equation editor?\nWhat happened when you changed the placement hint on your figure from [h] to [t]?\nHow did adding a citation and recompiling feel compared to managing references in a GUI?"
  },
  {
    "objectID": "plaintext-authoring.html#overleaf-collaborative-latex-in-the-browser-5-min",
    "href": "plaintext-authoring.html#overleaf-collaborative-latex-in-the-browser-5-min",
    "title": "Plaintext Authoring",
    "section": "2.6 — Overleaf: Collaborative LaTeX in the Browser (5 min)",
    "text": "2.6 — Overleaf: Collaborative LaTeX in the Browser (5 min)\nOverleaf deserves special mention because it addresses the most common objection to LaTeX: collaboration.\n\nReal-time collaboration like Google Docs — multiple people can edit simultaneously\nNo local installation required — everything compiles in the cloud\nRich library of templates for journals, theses, CVs, posters: https://www.overleaf.com/latex/templates\nGit integration on paid plans — you can push/pull your Overleaf project to a Git repo\nTrack changes and comments — familiar to Word users\nFree tier is generous for individual use; paid plans add more collaborators\n\nMany universities provide institutional Overleaf subscriptions — check with your library.\nFor students in neuroscience, psychology, kinesiology, and biology who may not write LaTeX daily, Overleaf significantly lowers the barrier to entry. You get the typographic quality and structural rigor of LaTeX with a Google Docs-like editing experience.\n\nOther Online LaTeX Editors\n\nCoCalc — includes LaTeX, Jupyter, and a terminal\nPapeeria — lightweight alternative to Overleaf"
  },
  {
    "objectID": "plaintext-authoring.html#putting-it-all-together-choosing-your-workflow-4-min",
    "href": "plaintext-authoring.html#putting-it-all-together-choosing-your-workflow-4-min",
    "title": "Plaintext Authoring",
    "section": "2.7 — Putting It All Together: Choosing Your Workflow (4 min)",
    "text": "2.7 — Putting It All Together: Choosing Your Workflow (4 min)\nHere are three practical workflows you might adopt as a graduate student:\n\nWorkflow 1: Markdown + Pandoc (Simplest)\nBest for: drafts, short papers, course assignments, people who want minimal setup.\npaper.md + refs.bib → pandoc → paper.pdf or paper.docx\n\n\nWorkflow 2: LaTeX on Overleaf (Collaborative)\nBest for: thesis chapters, papers with co-authors, when a journal provides a LaTeX template.\npaper.tex + refs.bib → Overleaf (cloud) → paper.pdf\n\n\nWorkflow 3: LaTeX Locally with Git (Maximum Control)\nBest for: advanced users, large projects, integration with data analysis pipelines.\npaper.tex + refs.bib → latexmk → paper.pdf\n         ↑\n    version controlled with Git\n\n\nWorkflow 4: Hybrid (Common in Practice)\nDraft in Markdown (fast, low friction), then convert to LaTeX when the paper matures and you need fine-tuned formatting or a journal template.\ndraft.md → pandoc → paper.tex → edit in LaTeX → paper.pdf\nAll four approaches keep your source as plaintext. All four let you use Git. All four separate content from presentation."
  },
  {
    "objectID": "plaintext-authoring.html#breakout-exercise-3-the-full-pipeline-10-min",
    "href": "plaintext-authoring.html#breakout-exercise-3-the-full-pipeline-10-min",
    "title": "Plaintext Authoring",
    "section": "2.8 — Breakout Exercise 3: The Full Pipeline (10 min)",
    "text": "2.8 — Breakout Exercise 3: The Full Pipeline (10 min)\n\nTask: From Markdown Draft to Polished Outputs\nYou are given a Markdown file representing a short paper. Your tasks:\n\nCompile to PDF with Pandoc. Inspect the output.\nCompile to Word with Pandoc. Open in Word or LibreOffice. Confirm it looks reasonable.\nCompile to LaTeX with pandoc paper.md -o paper.tex. Open the .tex file and look at what Pandoc generated.\nEdit the .tex file: adjust figure placement, tweak table formatting, or add a LaTeX-specific feature like \\pagebreak.\nCompile the edited .tex to PDF: latexmk -pdf paper.tex\n\n\n\nStarter File: exercise3.md\n---\ntitle: \"Visual Search Asymmetry in Threat Detection\"\nauthor: \"A. Student\"\ndate: \"2025-02-15\"\nabstract: |\n  We tested whether threatening stimuli (snakes) are detected\n  faster than non-threatening stimuli (flowers) in a visual\n  search task. Results supported the threat superiority effect.\nbibliography: refs3.bib\ncsl: apa.csl\ngeometry: margin=1in\nfontsize: 12pt\n---\n\n# Introduction\n\nThe threat superiority effect refers to the faster detection of\nthreatening stimuli in visual search [@ohman2001fears]. This has\nbeen demonstrated for snakes [@ohman2001fears], spiders\n[@rakison2009does], and angry faces [@fox2000facial].\n\n# Methods\n\n## Participants\n\nForty undergraduate students (28 female, mean age = 19.8,\nSD = 1.2) participated for course credit.\n\n## Stimuli and Design\n\nSearch displays contained 8 items arranged in a circle. On\ntarget-present trials, one item was the target (snake or flower)\namong 7 distractors (mushrooms). We used a 2 (target: snake,\nflower) × 2 (target presence: present, absent) design.\n\n## Data Analysis\n\nReaction times shorter than 200 ms or longer than 2000 ms were\nexcluded (1.8% of trials). We computed mean RTs for correct\nresponses and analyzed them with a repeated-measures ANOVA:\n\n$$F = \\frac{MS_{between}}{MS_{within}}$$\n\n# Results\n\nMean reaction times are shown in Table 1.\n\n| Target  | Present     | Absent      |\n|---------|-------------|-------------|\n| Snake   | 612 (89)    | 831 (102)   |\n| Flower  | 698 (94)    | 854 (110)   |\n\n: Mean reaction times in ms (SD in parentheses). {#tbl:rts}\n\nThere was a significant main effect of target type,\n$F(1, 39) = 14.2$, $p &lt; .001$, $\\eta_p^2 = .27$.\n\n# Discussion\n\nOur findings replicate the threat superiority effect\n[@ohman2001fears]. Snake targets were detected approximately\n86 ms faster than flower targets.\n\n# References\n\n\nDebrief\n\nYou just went from one source file to three output formats in about 60 seconds of terminal commands.\nYou then had the option to “eject” to LaTeX for fine-tuning. No information was lost.\nAsk yourself: could you do this in Word?"
  },
  {
    "objectID": "plaintext-authoring.html#quick-reference-card-and-resources-2-min",
    "href": "plaintext-authoring.html#quick-reference-card-and-resources-2-min",
    "title": "Plaintext Authoring",
    "section": "2.9 — Quick Reference Card and Resources (2 min)",
    "text": "2.9 — Quick Reference Card and Resources (2 min)\n\nEssential Terminal Commands\n# Pandoc: Markdown to PDF\npandoc paper.md --citeproc -o paper.pdf\n\n# Pandoc: Markdown to Word\npandoc paper.md --citeproc -o paper.docx\n\n# Pandoc: Markdown to LaTeX\npandoc paper.md -s -o paper.tex\n\n# LaTeX: compile with automatic re-runs\nlatexmk -pdf paper.tex\n\n# LaTeX: clean up auxiliary files\nlatexmk -c\n\n\nRecommended Tools\n\n\n\nTool\nWhat it does\nLink\n\n\n\n\nPandoc\nUniversal document converter\nhttps://pandoc.org/\n\n\nTeX Live\nFull LaTeX distribution (Linux/Windows)\nhttps://tug.org/texlive/\n\n\nMacTeX\nTeX Live for macOS\nhttps://tug.org/mactex/\n\n\nOverleaf\nCollaborative LaTeX editor in the browser\nhttps://www.overleaf.com/\n\n\nZotero\nReference manager (exports .bib)\nhttps://www.zotero.org/\n\n\nBetter BibTeX\nZotero plugin for clean .bib export\nhttps://retorque.re/zotero-better-bibtex/\n\n\nDetexify\nDraw a symbol → get LaTeX code\nhttps://detexify.kirelabs.org/\n\n\nTeXstudio\nLocal LaTeX editor with preview\nhttps://www.texstudio.org/\n\n\nVS Code + LaTeX Workshop\nLaTeX editing in VS Code\nhttps://marketplace.visualstudio.com/items?itemName=James-Yu.latex-workshop\n\n\n\n\n\nFurther Learning\n\nOverleaf’s LaTeX tutorials (excellent for beginners): https://www.overleaf.com/learn\nThe Not So Short Introduction to LaTeX2e (classic free guide): search CTAN for “lshort”\nLaTeX Wikibook: https://en.wikibooks.org/wiki/LaTeX\nPandoc User’s Guide: https://pandoc.org/MANUAL.html\nLaTeX StackExchange (Q&A community): https://tex.stackexchange.com/\nBibTeX entry types and fields: https://www.bibtex.com/e/entry-types/"
  },
  {
    "objectID": "plaintext-authoring.html#summary-what-you-can-now-do",
    "href": "plaintext-authoring.html#summary-what-you-can-now-do",
    "title": "Plaintext Authoring",
    "section": "Summary: What You Can Now Do",
    "text": "Summary: What You Can Now Do\nAfter these two lectures, you should be able to:\n\nExplain why plaintext authoring is valuable for reproducibility, portability, and archival.\nWrite a scientific document in Markdown with sections, citations, equations, and figures.\nUse Pandoc to convert that document to PDF, Word, or HTML.\nWrite a LaTeX document directly, with equations, figures, tables, and a bibliography.\nUse Overleaf for collaborative LaTeX editing.\nChoose the right workflow for a given writing task.\nConvert between formats as needed — including generating a .docx when a journal requires it.\n\nThe key takeaway: your source of truth should be plaintext. Everything else — PDF, Word, HTML — is an output format that you generate from that source. This gives you control, longevity, and quality."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction to the Course",
    "section": "",
    "text": "Welcome! I’m glad you’re here.\nThis is Psychology 9040: Scientific Computing, for FW25, Jan-Apr 2026.\nBring your computer to class! We will be writing code.\nCourse website: https://gribblelab.org/9040"
  },
  {
    "objectID": "intro.html#course-goals",
    "href": "intro.html#course-goals",
    "title": "Introduction to the Course",
    "section": "Course Goals",
    "text": "Course Goals\nIn this one-semester graduate course you will learn skills in scientific computing—tools and techniques that you can use in your own research. You will learn to program using Python, which is a high-level programming language with many libraries that provide a rich ecosystem for scientific computing. If you want to use a different language in the course you are welcome to but I will focus on Python in class. Having said that, as much as I can I will teach concepts in a way that are language-agnostic.\nThe course is designed to achieve three primary goals:\n\nYou will learn to write code in a high-level language (Python)\nYou will learn to think computationally and algorithmically about data analysis\nYou will learn some common data analysis techniques, which will give you a foundation from which to learn more complex scientific computing skills to suit your own research goals"
  },
  {
    "objectID": "intro.html#topics",
    "href": "intro.html#topics",
    "title": "Introduction to the Course",
    "section": "Topics",
    "text": "Topics\nIn the first part of the course you will learn how to write code. The topics we will cover are common to any high-level language including Python, MATLAB, R, Javascript, C, Julia, Go, Swift, etc. All high level languages have things like numbers, strings, arrays, loops, if-statements. Languages differ in their syntax, in the names of common functions, and sometimes in some other subtle ways (e.g. passing by reference vs passing by value) but otherwise, all high-level languages basically work in the same way. Learning these fundamental concepts of high-level programming languages using one language will enable you to learn other languages as well in the future.\nThe other aspect of programming that you will learn is how to think algorithmically about solving problems and completing tasks with computers. In general there are two reasons to use a computer to perform a given task, (1) because the task would take too long by hand (e.g. churning through processing a huge amount of data), and (2) because the computer can do something clever that you cannot do yourself (e.g. applying complex algorithms to a dataset).\nIn learning the fundamentals of high-level programming languages (data types, loops, conditionals, etc) we will sometimes practice writing code to solve little toy problems. This will start to teach you how to think algorithmically. Think about it like learning to play a musical instrument. You don’t start by learining to play Beethoven. You start learning basic skills by playing scales, arpeggios, different key signatures, etc. Building up basic skills using toy problems is a convenient path towards using coding skills to solve real-world programming problems in the context of your own thesis research.\nWe will also practice and learn by using code to answer questions about data. Some of the data will be from real experiments and some will be fictitious. The goal will be to answer a series of questions by writing code that performs operations on the data (reorganization, summarising, counting, calculating, processing, plotting, etc) and writing a short summary of your findings. This mimics how you will be using your coding skills in your own research going forward.\n\nFundamentals of Coding\n\ndigital representation of data\nbasic data types, operators, & expressions\ncontrol flow & conditionals\nfunctions\ncomplex data types\nfile input & output\ngraphical displays of data\nobject oriented programming (OOP)\n\n\n\nReproducibility & Replicability\n\nPython venvs (virtual environments)\nCode versioning using Git & GitHub\norganization of code and data\ndata analysis workflow\n\n\n\nTopics in Data Analysis\n\nsampling, signal processing, & filtering data\nstatistical tests (parametric vs resampling/boostrapping/randomization)\nfitting models to data\nsimulating dynamical systems\n\nBy building upon the foundational knowledge and skills you have acquired in this course, you will be able to learn other techniques in programming and in data analysis as your scientific research progresses."
  },
  {
    "objectID": "hw/hw06.html",
    "href": "hw/hw06.html",
    "title": "Homework 6",
    "section": "",
    "text": "Due: Mar 1 by 11:59 pm eastern standard time\nSubmit a single file called name_06.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_06.py"
  },
  {
    "objectID": "hw/hw06.html#matplotlib-exercises",
    "href": "hw/hw06.html#matplotlib-exercises",
    "title": "Homework 6",
    "section": "Matplotlib exercises",
    "text": "Matplotlib exercises\n\nDefine a 1D array x containing 10 values starting at 0, ending at 0.9, in increments of 0.1. Define a vector y that is equal to np.sin(2 * np.pi * x). Generate a line plot with x on the horizontal axis and y on the vertical axis. Use blue circles at each data point (markersize of 8.0), connected by blue solid lines, with a linewidth of 2.0. Label the horizontal axis x and the vertical axis y. Set the range on the horizontal axis so it goes from 0 to 0.9 in steps of 0.1, and on the vertical axis so it goes from -1 to 1 in steps of 0.2.\n\n\n\n\n\n\n\n\n\nDefine 1D arrays y1 equal to [1,2,3,4,4], y2 equal to [1,5,6,8,10], and y3 equal to [5,4,2,1,1]. Generate a multi-line plot using squares (markersize 6.0) connected with solid lines (linewidth 1.0). Label the axes as shown, and set axis limits and axis ticks as shown. Add a legend as shown. The y1 colour is blue, the y2 colour is red, and the y3 colour is magenta.\n\n\n\n\n\n\n\n\n\nDefine a 100-length 1D array x starting at 1 and ending at 100 in increments of 1. Define y equal to (x * 0.15) + N where N is a 100 element 1D array of random values chosen from a gaussian distribution with mean 0.0 and standard deviation 0.5. Let z be equal to ((x * 0.05) + 2) + N2 where N2 is a 100 element 1D array of random values chosen from a gaussian distribution with mean 0.0 and standard deviation 2.0. Generate a scatterplot as shown below, using filled circles (markersize 3.0). The y colour is blue and the z colour is red. Pay attention to the axis labels, tick marks, and ranges. At the beginning of your answer set the random seed (once) to be equal to 9040 so that we all get the same random values, using np.random.seed(9040).\n\n\n\n\n\n\n\n\n\nRe-plot the data from Question 3 using subplots, as shown below. Try to replicate the axis limits, and axis labeling. Use boldface font to add a title to each subplot (A, B, and C, aligned to the left of each subplot as shown below).\nHint: adjust the hspace parameter for subplots so that the subplots don’t overlap, e.g. plt.subplots_adjust(hspace=0.6).\nHint: ax.spines[\"top\"].set_visible(False) will turn off the top part of the box outlining each plot.\nHint: fig = plt.figure() and then ax1 = fig.add_subplot(2,2,(1,2)) will generate a subplot that spans cells 1 and 2 (the top row) of the 2x2 grid. Then ax2 = fig.add_subplot(2,2,3) and ax3 = fig.add_subplot(2,2,4) will define the lower two sublots.\nHint: the legend() method of an axis has an option that will remove the frame outline: frameon=False\n\n\n\n\n\n\n\n\n\n\nDo your best to replicate all of the elements of the Figure. If you can’t replicate every little part of it don’t worry, but challenge yourself to try to get as close as you can. I will post a sample solution after the deadline."
  },
  {
    "objectID": "hw/hw04.html",
    "href": "hw/hw04.html",
    "title": "Homework 4",
    "section": "",
    "text": "Due: Feb 8 by 11:59 pm eastern standard time\nSubmit a single file called name_04.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_04.py\n\nChoose any one of the “Slighly more challenging problems” listed in the Advent of Code coding exercises. Write a Python script to complete both part 1 and part 2 of the problem you choose. Submit only your code, you don’t need to submit your puzzle input.\nIf you are already Python experienced and you want to try one of the “more challenging problems” instead, that would be fine as well.\nIf you have never programmed anything before this course and you wish to choose one of the “Easiest problems” that would be ok as well."
  },
  {
    "objectID": "hw/hw02.html",
    "href": "hw/hw02.html",
    "title": "Homework 2",
    "section": "",
    "text": "Due: Jan 25 by 11:59 pm eastern standard time\nSubmit a single file called name_02.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_02.py\n\nWrite a Python program to complete the Nth Prime number exercise.\nMake sure it produces the correct output given the example inputs."
  },
  {
    "objectID": "homeworks.html",
    "href": "homeworks.html",
    "title": "A Note about Homeworks",
    "section": "",
    "text": "The reason I assign homework to you each week is not because I want to see the code that you write.\nThe purpose of homework is for you to do the intellectual work required to write the code.\nIf you choose to use an AI tool (e.g. ChatGPT) to write your homework code then you will probably get a very good grade in this course but you will not have done the intellectual work.\nIn my experience (more than three decades in a university environment), reading other people’s code (or code that an AI tool wrote) is not a substitute for doing the intellectual work required to produce your own code.\nIt simply isn’t.\nIf you take this course, and you get a good grade, your supervisors / bosses / collaborators will expect you to have mastered the material and skills that are advertised in the (public) course outline, and that are reflected in the homework assignments that you hand in.\nYour grade in this course is not the goal. The intellectual work is the goal. If you don’t want to do the intellectual work, don’t take the course. It would be a waste of your time and mine.\nIf you are having difficulty with the work, come and see me or the TA, we will be absolutely pleased to help!\n—P"
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "Git & GitHub",
    "section": "",
    "text": "First, if you don’t have a GitHub account already, go and sign up for a (free) GitHub account.\nThen, double-check that you have installed git as part of the setup instructions. Open up a terminal and type:\ngit --version\nand you should get something like:\ngit version 2.34.0\nIt doesn’t much matter if the version number isn’t identical to the one above."
  },
  {
    "objectID": "git.html#setup",
    "href": "git.html#setup",
    "title": "Git & GitHub",
    "section": "",
    "text": "First, if you don’t have a GitHub account already, go and sign up for a (free) GitHub account.\nThen, double-check that you have installed git as part of the setup instructions. Open up a terminal and type:\ngit --version\nand you should get something like:\ngit version 2.34.0\nIt doesn’t much matter if the version number isn’t identical to the one above."
  },
  {
    "objectID": "git.html#tutorials-intros",
    "href": "git.html#tutorials-intros",
    "title": "Git & GitHub",
    "section": "Tutorials / Intros",
    "text": "Tutorials / Intros\n\nabout GitHub and Git by GitHub docs\ngit-novice by software carpentry\nhello world by GitHub docs\nGit Cheat Sheet by GitHub Education\nGit project page\nVersion Control and Git by Kieran Healy\nThe Version Control Book: Track, organize and share your work: An introduction to Git for research"
  },
  {
    "objectID": "functions_file_io.html",
    "href": "functions_file_io.html",
    "title": "Functions, File input & output",
    "section": "",
    "text": "Learning with Python 3 chapter 4: Functions\nThink Python Chapter 3\nPython for Data Analysis chapter 3.2: Functions\nPython for Data Analysis chapter 3.3: Files and the Operating System\nPython for Data Analysis chapter 6: Data Loading, Storage, and File Formats"
  },
  {
    "objectID": "functions_file_io.html#readings",
    "href": "functions_file_io.html#readings",
    "title": "Functions, File input & output",
    "section": "",
    "text": "Learning with Python 3 chapter 4: Functions\nThink Python Chapter 3\nPython for Data Analysis chapter 3.2: Functions\nPython for Data Analysis chapter 3.3: Files and the Operating System\nPython for Data Analysis chapter 6: Data Loading, Storage, and File Formats"
  },
  {
    "objectID": "control_flow_and_complex_data_types.html",
    "href": "control_flow_and_complex_data_types.html",
    "title": "Control Flow & Complex data types",
    "section": "",
    "text": "Here we will learn above several ways to specify the flow of information as your code gets executed. We will learn about loops, which are constructs that allow you to repeat blocks of code multiple times, typically while changing the values of variables inside the repeating block. We will learn about conditionals, which allow you to execute different branches of code depending on the values of variables.\n\n\n\nLearning with Python 3 chapter 5: Conditionals\nLearning with Python 3 chapter 7: Iteration\nPython for Data Analysis chapter 3: Built-in Data Structures, Functions, and Files\nPython for Data Analysis chapter 4: NumPy Basics: Arrays and Vectorized Computation\nPython for Data Analysis chapter 5: Getting Started with pandas\nConditionals and recursion (you can ignore for now the section on recursion)\nControl Flow\n\n\n\n\nLoops are used when you have a chunk of code that you need to repeat over and over again, each time changing one (or more) parameters.\nThere are two kinds of loops: a for loop and a while loop. A for loop is used when you (or your code) know in advance of starting the loop, how many iterations to run through. A while loop is used when the number of iterations is not known in advance of starting the loop. You might use a for loop to load in a list of data files. You might use a while loop to iterate through an EEG waveform over samples (time) to search for the first value that exceeds some baseline threshold.\nHere is a simple example for the purposes of demonstration. Let’s say you want to load data from 5 files, named data1.txt, data2.txt, …, data5.txt. Let’s say each file contains a one-dimensional array of 10 values. Let’s say you want to take the average of each data file and then report the overall mean and overall variance of those values. Here’s one way to do it:\n\n\n\nd1 = load(\"data1.txt\")\nd1m = mean(d1)\nd2 = load(\"data2.txt\")\nd2m = mean(d2)\nd3 = load(\"data3.txt\")\nd3m = mean(d3)\nd4 = load(\"data4.txt\")\nd4m = mean(d4)\nd5 = load(\"data5.txt\")\nd5m = mean(d5)\n\n# report overall mean and overall variance of 5 data file means\nalldata = [d1m, d2m, d3m, d4m, d5m]\ndatamean = mean(alldata)\ndatavar = var(alldata)\nprint(f\"mean={datamean:.3f} and variance={datavar:.3f}\")\n\nYou can see that there is a lot of repetition in this code. What if we had to load data from 1000 data files? There would be a lot of copying and pasting of code chunks. This is error prone and inefficient. Instead let’s use a for loop. A for loop allows you to repeat a block of code some predetermined number of times, and includes a counter so that you know which iteration of the loop is currently running. Here is what the code above would look like if we used a for loop:\n\nnfiles = 1000\nalldata = np.zeros(1000)\nfor i in range(nfiles):\n    d = load(\"data\" + str(i) + \".txt\")\n    alldata[i] = mean(d)\ndatamean = mean(alldata)\ndatavar = var(alldata)\nprint(f\"mean={datamean:.3f} and variance={datavar:.3f}\")\n\nNow all we would need to change if we have 1000 data files (or one million) is the value of our variable nfiles=1000 or nfiles=1e6—nothing else in the code would have to change. This makes our code much more resilient against programming errors.\nYou can see a for loop begins with the keyword for followed by a name of a variable (your choice) that will keep track of which iteration of the loop is currently running. Then for word in followed by a list of values to be iterated through. Next is the block of code to be repeated. Note that in Python, blocks of code like this are denoted using indentation. Python is very fussy indeed about indentation.\n\nfor i in range(1,15,3):\n    print(f\"i={i}\")\n\ni=1\ni=4\ni=7\ni=10\ni=13\n\n\nFor loops are executed in a serial fashion, one repetition after another.\n\n\n\nThere is a second sort of loop called a while loop. This kind of loop is typically used when the number of iterations is not known in advance. A while loop keeps repeating until the value of a logical expression changes from TRUE to FALSE (changes from 1 to 0). As a little demo, here is an example of a while loop that prints out successive integers starting from 1, until they exceed a critical value, in this case 10:\n\ni = 1\nwhile (i &lt; 9):\n    print(f\"i={i}\")\n    i = i + 1\n\ni=1\ni=2\ni=3\ni=4\ni=5\ni=6\ni=7\ni=8\n\n\nThe expression that determines whether a while loop will continue repeating can be any valid Python expression that evaluates to a boolean (true or false).\nFor both for loops and while loops, there are two keywords to know about that can break you out of a loop (break) and can move you to the next iteration of the loop (continue). I tend not to use these, but some people find them useful."
  },
  {
    "objectID": "control_flow_and_complex_data_types.html#readings",
    "href": "control_flow_and_complex_data_types.html#readings",
    "title": "Control Flow & Complex data types",
    "section": "",
    "text": "Learning with Python 3 chapter 5: Conditionals\nLearning with Python 3 chapter 7: Iteration\nPython for Data Analysis chapter 3: Built-in Data Structures, Functions, and Files\nPython for Data Analysis chapter 4: NumPy Basics: Arrays and Vectorized Computation\nPython for Data Analysis chapter 5: Getting Started with pandas\nConditionals and recursion (you can ignore for now the section on recursion)\nControl Flow"
  },
  {
    "objectID": "control_flow_and_complex_data_types.html#loops",
    "href": "control_flow_and_complex_data_types.html#loops",
    "title": "Control Flow & Complex data types",
    "section": "",
    "text": "Loops are used when you have a chunk of code that you need to repeat over and over again, each time changing one (or more) parameters.\nThere are two kinds of loops: a for loop and a while loop. A for loop is used when you (or your code) know in advance of starting the loop, how many iterations to run through. A while loop is used when the number of iterations is not known in advance of starting the loop. You might use a for loop to load in a list of data files. You might use a while loop to iterate through an EEG waveform over samples (time) to search for the first value that exceeds some baseline threshold.\nHere is a simple example for the purposes of demonstration. Let’s say you want to load data from 5 files, named data1.txt, data2.txt, …, data5.txt. Let’s say each file contains a one-dimensional array of 10 values. Let’s say you want to take the average of each data file and then report the overall mean and overall variance of those values. Here’s one way to do it:\n\n\n\nd1 = load(\"data1.txt\")\nd1m = mean(d1)\nd2 = load(\"data2.txt\")\nd2m = mean(d2)\nd3 = load(\"data3.txt\")\nd3m = mean(d3)\nd4 = load(\"data4.txt\")\nd4m = mean(d4)\nd5 = load(\"data5.txt\")\nd5m = mean(d5)\n\n# report overall mean and overall variance of 5 data file means\nalldata = [d1m, d2m, d3m, d4m, d5m]\ndatamean = mean(alldata)\ndatavar = var(alldata)\nprint(f\"mean={datamean:.3f} and variance={datavar:.3f}\")\n\nYou can see that there is a lot of repetition in this code. What if we had to load data from 1000 data files? There would be a lot of copying and pasting of code chunks. This is error prone and inefficient. Instead let’s use a for loop. A for loop allows you to repeat a block of code some predetermined number of times, and includes a counter so that you know which iteration of the loop is currently running. Here is what the code above would look like if we used a for loop:\n\nnfiles = 1000\nalldata = np.zeros(1000)\nfor i in range(nfiles):\n    d = load(\"data\" + str(i) + \".txt\")\n    alldata[i] = mean(d)\ndatamean = mean(alldata)\ndatavar = var(alldata)\nprint(f\"mean={datamean:.3f} and variance={datavar:.3f}\")\n\nNow all we would need to change if we have 1000 data files (or one million) is the value of our variable nfiles=1000 or nfiles=1e6—nothing else in the code would have to change. This makes our code much more resilient against programming errors.\nYou can see a for loop begins with the keyword for followed by a name of a variable (your choice) that will keep track of which iteration of the loop is currently running. Then for word in followed by a list of values to be iterated through. Next is the block of code to be repeated. Note that in Python, blocks of code like this are denoted using indentation. Python is very fussy indeed about indentation.\n\nfor i in range(1,15,3):\n    print(f\"i={i}\")\n\ni=1\ni=4\ni=7\ni=10\ni=13\n\n\nFor loops are executed in a serial fashion, one repetition after another.\n\n\n\nThere is a second sort of loop called a while loop. This kind of loop is typically used when the number of iterations is not known in advance. A while loop keeps repeating until the value of a logical expression changes from TRUE to FALSE (changes from 1 to 0). As a little demo, here is an example of a while loop that prints out successive integers starting from 1, until they exceed a critical value, in this case 10:\n\ni = 1\nwhile (i &lt; 9):\n    print(f\"i={i}\")\n    i = i + 1\n\ni=1\ni=2\ni=3\ni=4\ni=5\ni=6\ni=7\ni=8\n\n\nThe expression that determines whether a while loop will continue repeating can be any valid Python expression that evaluates to a boolean (true or false).\nFor both for loops and while loops, there are two keywords to know about that can break you out of a loop (break) and can move you to the next iteration of the loop (continue). I tend not to use these, but some people find them useful."
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Sample Code",
    "section": "",
    "text": "fizzbuzz.py\nis_it_prime.py\np092.py\nfileio.py\nshapes.py"
  },
  {
    "objectID": "clean_code.html",
    "href": "clean_code.html",
    "title": "Reproducibility & Replicability II: clean code",
    "section": "",
    "text": "Writing small scripts to solve toy programming puzzles is one thing, but writing a large amount of inter-connected code to analyse a dataset is quite another. What’s more organizing the data itself is something that can have a big impact on the organization and clarity of the code. It’s worth talking about and thinking about some basic principles for organizing data and code for realistic scenarios such as scientific experiments and data analysis work.\nI want you to read the following:\n\nWriting clean code guide from the Jörn Diedrichsen lab blog\n\n\n\n\n\ncode should work with zero (or extremely minimal) configuration by a newcomer\nit should be clear how to run the code, how the pieces of the code work together, and what the results are\nthe more dependencies that exist in your code, the higher the probability that it will not work in the future. For Python, the uv or venv tools can help with this by allowing you to specify version numbers for all libraries that you use with your code, and it lets you package that specification (a pyproject.toml or requirements.txt file) together with your code itself.\ncode and the data it operates on should be packaged together and should “just work”\ndata should be organized in files and folders with informative filenames and rational folder structures\ncode should be clear so that others can understand how it works (and “others” includes you in the future)\n\n\n\n\nThink about the stages of processing between raw data, intermediate data structures, and “final” data used for figures and statistical analyses.\n\n\n\nfrom the Writing clean code guide by Jörn Diedrichsen\n\n\nIt should be crystal clear how to get each Figure or statistical analysis from data + code. Jörn suggests it and I agree: write out on a piece of paper what this directed graph looks like for your paper/project.\n\n\n\n\ncode should reside in a publicly accessible repository (e.g. on GitHub)\neach Figure and each statistical analysis should be reproducible by running a single script/function without changes\ndata should accompany the code\n\n\n\n\nGitHub is a version control system and code-sharing platform that allows you to track changes to your code over time and collaborate with others. You can use GitHub to store and manage your code, data analysis notebooks, and even data (though not gigantic amounts of data), ensuring you can revert to previous versions if needed. GitHub works well with a number of other useful programs like Visual Studio Code and the online LaTeX document system Overleaf.\n\nGet Started with GitHub\nGitHub Skills\n\n\n\n\nOther resources include:\n\nbook: Clean Code: A Handbook of Agile Software Craftsmanship by Robert Martin\na shorter book: A philosophy of software design by John Ousterhout, (and an accompanying website)"
  },
  {
    "objectID": "clean_code.html#principles-of-clean-code",
    "href": "clean_code.html#principles-of-clean-code",
    "title": "Reproducibility & Replicability II: clean code",
    "section": "",
    "text": "Writing small scripts to solve toy programming puzzles is one thing, but writing a large amount of inter-connected code to analyse a dataset is quite another. What’s more organizing the data itself is something that can have a big impact on the organization and clarity of the code. It’s worth talking about and thinking about some basic principles for organizing data and code for realistic scenarios such as scientific experiments and data analysis work.\nI want you to read the following:\n\nWriting clean code guide from the Jörn Diedrichsen lab blog\n\n\n\n\n\ncode should work with zero (or extremely minimal) configuration by a newcomer\nit should be clear how to run the code, how the pieces of the code work together, and what the results are\nthe more dependencies that exist in your code, the higher the probability that it will not work in the future. For Python, the uv or venv tools can help with this by allowing you to specify version numbers for all libraries that you use with your code, and it lets you package that specification (a pyproject.toml or requirements.txt file) together with your code itself.\ncode and the data it operates on should be packaged together and should “just work”\ndata should be organized in files and folders with informative filenames and rational folder structures\ncode should be clear so that others can understand how it works (and “others” includes you in the future)\n\n\n\n\nThink about the stages of processing between raw data, intermediate data structures, and “final” data used for figures and statistical analyses.\n\n\n\nfrom the Writing clean code guide by Jörn Diedrichsen\n\n\nIt should be crystal clear how to get each Figure or statistical analysis from data + code. Jörn suggests it and I agree: write out on a piece of paper what this directed graph looks like for your paper/project.\n\n\n\n\ncode should reside in a publicly accessible repository (e.g. on GitHub)\neach Figure and each statistical analysis should be reproducible by running a single script/function without changes\ndata should accompany the code\n\n\n\n\nGitHub is a version control system and code-sharing platform that allows you to track changes to your code over time and collaborate with others. You can use GitHub to store and manage your code, data analysis notebooks, and even data (though not gigantic amounts of data), ensuring you can revert to previous versions if needed. GitHub works well with a number of other useful programs like Visual Studio Code and the online LaTeX document system Overleaf.\n\nGet Started with GitHub\nGitHub Skills\n\n\n\n\nOther resources include:\n\nbook: Clean Code: A Handbook of Agile Software Craftsmanship by Robert Martin\na shorter book: A philosophy of software design by John Ousterhout, (and an accompanying website)"
  },
  {
    "objectID": "concepts.html",
    "href": "concepts.html",
    "title": "Concepts",
    "section": "",
    "text": "installing our development environment"
  },
  {
    "objectID": "concepts.html#week-1",
    "href": "concepts.html#week-1",
    "title": "Concepts",
    "section": "",
    "text": "installing our development environment"
  },
  {
    "objectID": "concepts.html#week-2",
    "href": "concepts.html#week-2",
    "title": "Concepts",
    "section": "Week 2",
    "text": "Week 2\n\nediting a .py Python program and executing it in the shell\nthe iPython REPL\nuv add ipython to install; and then uv run ipython to launch\nexpressions, operators, values, & variables\noperator precedence\nusing brackets ( and ) to override operator precedence\nnumeric vs character string data types\nvariables: str, int, float, bool, inspect using type()\nconversion: str(), int(), float()\noperators: + - * /, **, modulus %\nlogical operators &lt; &gt; == &gt;= &lt;= != and or not True False\nimport statements—for example, from math import cos\nprint() and formatted output using f-strings\ngetting input from the user using input()\ncommenting code using #\nreserved keywords in Python (e.g. for, return, etc)\ngetting help using help()\nVisual Studio Code"
  },
  {
    "objectID": "concepts.html#week-3",
    "href": "concepts.html#week-3",
    "title": "Concepts",
    "section": "Week 3",
    "text": "Week 3\n\nconditionals if elif else\nloops using while and for\nrange() versus list types\n\n“range objects are a specific type of sequence in Python, they behave similarly to lists or tuples but are immutable and lazy”\n\nthe FizzBuzz coding exercise\nzero-based indexing in Python\nputting it all together: testing primeness of integers"
  },
  {
    "objectID": "concepts.html#week-4",
    "href": "concepts.html#week-4",
    "title": "Concepts",
    "section": "Week 4",
    "text": "Week 4\n\nlists in Python\nlist comprehensions e.g. five_odd_numbers = [i for i in range(1,11,2)]\nin Python list variables are pointers\nb = a vs b = a.copy()\nb == a vs b is a\nother complex data types in Python: tuples, ranges, dictionaries, and sets\nwriting your own functions in Python\n\ndefining a function\nfunction header\ninput arguments\nthe work\nreturning output(s)\nvariable scope\nnamed inputs\ndefault values\n\nthe idea of modularity of code"
  },
  {
    "objectID": "concepts.html#week-5",
    "href": "concepts.html#week-5",
    "title": "Concepts",
    "section": "Week 5",
    "text": "Week 5\n\nNumPy arrays\ncreating arrays\nnp.zeros() and np.ones()\nshape of arrays using np.shape()\nmultidimensional arrays\nvectorized operations on arrays\nslicing & indexing into arrays\nfile input & output: low-level\n\nall files are binary, a series of 8-bit bytes\nASCII encoding (and utf-8 more modern version)\nusing hex editor to view a file as hexadecimal bytes\nPython defaults: 32-bit int, 64-bit float, 8-bit char\nlittle-endian vs big-endian byte ordering (sys.byteorder to check)\nusing numpy to read and write binary bytes by specifying dtype\n\nfile input & output: high-level using NumPy & pandas"
  },
  {
    "objectID": "concepts.html#week-6",
    "href": "concepts.html#week-6",
    "title": "Concepts",
    "section": "Week 6",
    "text": "Week 6\n\nprocedural programming: functions acting on data structures\nobject-oriented programming (OOP): classes & objects encapsulate attributes & methods\nhierarchical organization of Classes (and superclasses and subclasses)\nattributes (data)\nmethods (functions)\nthe __init__() method and the self variable\ninheritance\noverriding inherited methods\npolymorphism\nsuper().__init__()\nspecial methods: __str__() and __repr__()\ncopying objects\n\nshallow copy using the copy module copy.copy()\ndeep copy using copy.deepcopy()\n\noperator overloading, e.g. __eq()__, __lt__(), __gt__()"
  },
  {
    "objectID": "digital_representation_of_data.html",
    "href": "digital_representation_of_data.html",
    "title": "Digital Representation of Data",
    "section": "",
    "text": "Learning with Python 3 chapter 1: The way of the program\nLearning with Python 3 chapter 2: Variables, expressions and statements\nPython for Data Analysis chapter 1: Preliminaries\nPython for Data Analysis chapter 2: Python Language Basics, iPython, and Jupyter Notebooks\n\n\n\n\nThe way of the program\nVariables, expressions, and statements\nPython Language Basics\nHolding a Program in One’s Head"
  },
  {
    "objectID": "digital_representation_of_data.html#high-level-vs-low-level-languages",
    "href": "digital_representation_of_data.html#high-level-vs-low-level-languages",
    "title": "Digital Representation of Data",
    "section": "High-level vs low-level languages",
    "text": "High-level vs low-level languages\nThe CPU (central processing unit) chip(s) that sit on the motherboard of your computer is the piece of hardware that actually executes instructions. A CPU only understands a relatively low-level language called machine code. Often machine code is generated automatically by translating code written in assembly language, which is a low-level programming language that has a relatively direcy relationship to machine code (but is more readable by a human). A utility program called an assembler is what translates assembly language code into machine code.\nIn this course we will be learning how to program in Python, which is a high-level programming language. The “high-level” refers to the fact that the language has a strong abstraction from the details of the computer (the details of the machine code). A “strong abstraction” means that one can operate using high-level instructions without having to worry about the low-level details of carrying out those instructions.\nAn analogy is motor skill learning. A high-level language for human action might be drive your car to the grocery store and buy apples. A low-level version of this might be something like: (1) walk to your car; (2) open the door; (3) start the ignition; (4) put the transmission into Drive; (5) step on the gas pedal, and so on. An even lower-level description might involve instructions like: (1) activate your gastrocnemius muscle until you feel 2 kg of pressure on the underside of your right foot, maintain this pressure for 2.7 seconds, then release (stepping on the gas pedal); (2) move your left and right eyeballs 27 degrees to the left (check for oncoming cars); (3) activate your pectoralis muscle on the right side of your chest and simultaneously squeeze the steering wheel with the fingers on your right hand (steer the car to the left); and so on.\nFor scientific programming, we would like to deal at the highest level we can, so that we can avoid worrying about the low-level details. We might for example want to plot a line in a Figure and colour it blue. We don’t want to have to program the low-level details of how each pixel on the screen is set, and how to generate each letter of the font that is used to specify the x-axis label.\nAs an example, here is a hello, world program written in a variety of languages, just to give you a sense of things. You can see the high-level languages like MATLAB, Python and R are extremely readable and understandable, even though you may not know anything about these languages (yet). The C code is less readable, there are lots of details one may not know about... and the assembly language example is a bit of a nightmare, obviously too low-level for our needs here.\nPython\nprint(\"hello, world\")\nMATLAB\ndisp('hello, world')\nR\ncat(\"hello, world\\n\")\nJavascript\ndocument.write(\"hello, world\");\nFortran\nprint *,\"hello, world\"\nC\n#include &lt;stdio.h&gt;\nint main (int argc, char *argv[]) {\n  printf(\"hello, world\\n\");\n  return 0;\n}\n8086 Assembly language\n; this example prints out  \"hello world!\" by writing directly to video memory.\n; first byte is ascii character, next is character attribute (8 bit value)\n; high 4 bits set background color and low 4 bits set foreground color.\n \norg 100h\n\n; set video mode    \nmov ax, 3     ; text mode 80x25, 16 colors, 8 pages (ah=0, al=3)\nint 10h       ; do it!\n\n; cancel blinking and enable all 16 colors:\nmov ax, 1003h\nmov bx, 0\nint 10h\n\n; set segment register:\nmov     ax, 0b800h\nmov     ds, ax\n\n; print \"hello world\"\n\nmov [02h], 'H'\nmov [04h], 'e'\nmov [06h], 'l'\nmov [08h], 'l'\nmov [0ah], 'o'\nmov [0ch], ','\nmov [0eh], 'W'\nmov [10h], 'o'\nmov [12h], 'r'\nmov [14h], 'l'\nmov [16h], 'd'\nmov [18h], '!'\n\n; color all characters:\nmov cx, 12  ; number of characters.\nmov di, 03h ; start from byte after 'h'\n\nc:  mov [di], 11101100b   ; light red(1100) on yellow(1110)\n    add di, 2 ; skip over next ascii code in vga memory.\n    loop c\n\n; wait for any key press:\nmov ah, 0\nint 16h\n\nret"
  },
  {
    "objectID": "digital_representation_of_data.html#interpreted-vs-compiled-languages",
    "href": "digital_representation_of_data.html#interpreted-vs-compiled-languages",
    "title": "Digital Representation of Data",
    "section": "Interpreted vs compiled languages",
    "text": "Interpreted vs compiled languages\nSome languages like C and Fortran are compiled languages, meaning that we write code in C or Fortran, and then to run the code (to have the computer execute those instructions) we first have to translate the code into machine code, and then run the machine code. The utility function that performs this translation (compilation) is called a compiler. In addition to simply translating a high-level language into machine code, modern compilers will also perform a number of optimizations to ensure that the resulting machine code runs fast, and uses little memory. Typically we write a program in C, then compile it, and if there are no errors, we then run it. We deal with the entire program as a whole. Compiled program tend to be fast since the entire program is compiled and optimized as a whole, into machine code, and then run on the CPU as a whole.\nOther languages, like MATLAB, Python and R, are interpreted languages, meaning that we write code which is then translated, command by command, into machine language instructions which are run one after another. This is done using a utility called an interpreter. We don’t have to compile the whole program all together in order to run it. Instead we can run it one instruction at a time. Typically we do this in an interactive programming environment where we can type in a command, and observe the result, and then type a next command, etc. This is known as the read-eval-print (REPL) loop. This is advantageous for scientific programming, where we typically spend a lot of time exploring our data in an interactive way. One can of course run a program such as this in a batch mode, all at once, without the interactive REPL environment... but this doesn’t change the fact that the translation to machine code still happens one line at a time, each in isolation. Interpreted languages tend to be slow, because every single command is taken in isolation, one after the other, and in real time translated into machine code which is then executed in a piecemeal fashion.\nFor interactive programming, when we are exploring our data, interpreted languages like MATLAB, Python and R shine. They may be slow but it (typically) doesn’t matter, because what’s many orders of magnitude slower, is the firing of the neurons in our brain as we consider the output of each command and decide what to do next, how to analyse our data differently, what to plot next, etc. For batch programming (for example fMRI processing pipelines, or electrophysiological recording signal processing, or numerical optimizations, or statistical bootstrapping operations), where we want to run a large set of instructions all at once, without looking at the result of each step along the way, compiled languages really shine. They are much faster than interpreted languages, often several orders of magnitude faster. It’s not unusual for even a simple program written in C to run 100x or even 1000x faster than the same program written in MATLAB, Python or R.\nA 1000x speedup may not be very important when the program runs in 5 seconds (versus 5 milliseconds) but when a program takes 60 seconds to run in MATLAB, Python, or R, for example, things can start to get problematic.\nImagine you write some code to read in data from one subject, process that data, and write the result to a file, and that operation takes 60 seconds. Is that so bad? Not if you only have to run it once. Now let’s imagine you have 15 subjects in your group. Now 60 seconds is 15 minutes. Now let’s say you have 4 groups. Now 15 minutes is one hour. You run your program, go have lunch, and come back an hour later and you find there was an error. You fix the error and re-run. Another hour. Even if you get it right, now imagine your supervisor asks you to re-run the analysis 5 different ways, varying some parameter of the analysis (maybe filtering the data at a different frequency, for example). Now you need 5 hours to see the result. It doesn’t take a huge amount of data to run into this sort of situation.\nNow imagine if you could program this data processing pipeline in C instead, and you could achieve a 500x speedup (not unusual), now those 5 hours turn into 36 seconds (you could run your analysis twice and it would still take less time than listening to Stairway to Heaven a dozen times). All of a sudden it’s the difference between an overnight operation and a 30 second operation. That makes a big difference to the kind of work you can do, and the kinds of questions you can pursue.\nPython (when using NumPy) and MATLAB is pretty good about using optimized, compiled subroutines for certain operations (e.g. matrix algebra), so in many cases the difference between Python/MATLAB and C performance isn’t as great as it is for others. Python has add-ons, for example Numba, that with some work, enables one to essentially compile parts of Python code. In practice this can be tricky though. MATLAB also has a toolbox (called the MATLAB Coder) that will allow you to generate C code from your MATLAB code, so in principle you can take slow MATLAB code and generate faster, compiled C code."
  },
  {
    "objectID": "digital_representation_of_data.html#readings-1",
    "href": "digital_representation_of_data.html#readings-1",
    "title": "Digital Representation of Data",
    "section": "Readings",
    "text": "Readings\n\nplay with the IEEE-754 Floating Point Converter (e.g. lookup the representation of 0.1, 0.2, and 0.3)"
  },
  {
    "objectID": "digital_representation_of_data.html#binary",
    "href": "digital_representation_of_data.html#binary",
    "title": "Digital Representation of Data",
    "section": "Binary",
    "text": "Binary\nInformation on a digital computer is stored in a binary format. Binary format represents information using a series of 0s and 1s. If there are n digits of a binary code, one can represent 2^{n} bits of information.\nSo for example the binary number denoted by:\n0001\nrepresents the number 1.\n0010\nThis is a 4-bit code since there are 4 binary digits. The full list of all values that can be represented using a 4-bit code are shown in the Table below:\n\n\nCode\nprint(\"Decimal Binary\")\nprint(\"------- -------\")\nfor n in range(16):\n    print(f\"{n:7d} {n:04b}\")\n\n\nDecimal Binary\n------- -------\n      0 0000\n      1 0001\n      2 0010\n      3 0011\n      4 0100\n      5 0101\n      6 0110\n      7 0111\n      8 1000\n      9 1001\n     10 1010\n     11 1011\n     12 1100\n     13 1101\n     14 1110\n     15 1111\n\n\nSo with a 4-bit binary code one can represent 2^{4} = 16 different values (0-15). Each additional bit doubles the number of values one can represent. So a 5-bit code enables us to represent 32 distinct values, a 6-bit code 64, a 7-bit code 128 and an 8-bit code 256 values (0-255).\nAnother piece of terminology: a given sequence of binary digits that forms the natural unit of data for a given processor (CPU) is called a word.\nHave a look at the ASCII table. The standard ASCII table represents 128 different characters and the extended ASCII codes enable another 128 for a total of 256 characters. How many binary bits are used for each?"
  },
  {
    "objectID": "digital_representation_of_data.html#hexadecimal",
    "href": "digital_representation_of_data.html#hexadecimal",
    "title": "Digital Representation of Data",
    "section": "Hexadecimal",
    "text": "Hexadecimal\nYou will also see in the ASCII table that it gives the decimal representation of each character but also the Hexadecimal and Octal representations. The hexadecimal system is a base-16 code and the octal system is a base-8 code. Hex values for a single hexadecimal digit can range over:\n0 1 2 3 4 5 6 7 8 9 a b c d e f\nIf we use a 2-digit hex code we can represent 16^{2} = 256 distinct values. In computer science, engineering and programming, a common practice is to represent successive 4-bit binary sequences using single-digit hex codes:\n\n\nCode\nprint(\"Dec Bin  Hex\")\nprint(\"--- ---- ---\")\nfor n in range(16):\n    print(f\"{n:3d} {n:04b} {n:x}\")\n\n\nDec Bin  Hex\n--- ---- ---\n  0 0000 0\n  1 0001 1\n  2 0010 2\n  3 0011 3\n  4 0100 4\n  5 0101 5\n  6 0110 6\n  7 0111 7\n  8 1000 8\n  9 1001 9\n 10 1010 a\n 11 1011 b\n 12 1100 c\n 13 1101 d\n 14 1110 e\n 15 1111 f\n\n\nIf we have 8-bit binary codes we would use successive hex digits to represent each 4-bit word of the 8-bit byte (another piece of lingo):\n\n\nCode\nprint(\"Dec Bin      Hex\")\nprint(\"--- -------- ---\")\nfor n in range(3):\n    print(f\"{n:3d} {n:08b} {n:x}\")\nprint(\"    ...     \")\nfor n in range(253,256,1):\n    print(f\"{n:3d} {n:08b} {n:x}\")\n\n\nDec Bin      Hex\n--- -------- ---\n  0 00000000 0\n  1 00000001 1\n  2 00000010 2\n    ...     \n253 11111101 fd\n254 11111110 fe\n255 11111111 ff\n\n\nThe left chunk of 4-bit binary digits (the left word) is represented in hex as a single hex digit (0-f) and the next chunk of 4-bit binary digits (the right word) is represented as another single hex digit (0-f).\nHex is typically used to represent bytes (8-bits long) because it is a more compact notation than using 8 binary digits (hex uses just 2 hex digits)."
  },
  {
    "objectID": "digital_representation_of_data.html#floating-point-values",
    "href": "digital_representation_of_data.html#floating-point-values",
    "title": "Digital Representation of Data",
    "section": "Floating point values",
    "text": "Floating point values\nThe material above talks about the decimal representation of bytes in terms of integer values (e.g. 0-255). Frequently however in science we want the ability to represent real numbers on a continuous scale, for example 3.14159, or 5.5, or 0.123, etc. For this, the convention is to use floating point representations of numbers.\nThe idea behind the floating point representation is that it allows us to represent an approximation of a real number in a way that allows for a large number of possible values. Floating point numbers are represented to a fixed number of significant digits (called a significand) and then this is scaled using a base raised to an exponent:\ns~\\mathrm{x}~b^{e}\nThis is related to something you may have come across in high-school science, namely scientific notation. In scientific notation, the base is 10 and so a real number like 123.4 is represented as 1.234~\\mathrm{x}~10^{2}.\nIn computers there are different conventions for different CPUs but there are standards, like the IEEE 754 floating-point standard. As an example, a so-called single-precision floating point format is represented in binary (using a base of 2) using 32 bits (4 bytes) and a /double precision/ floating point number is represented using 64 bits (8 bytes). In C you can find out how many bytes are used for various types using the sizeof() function:\n#include &lt;stdio.h&gt;\nint main(int argc, char *argv[]) {\n  printf(\"a single precision float uses %ld bytes\\n\", sizeof(float));\n  printf(\"a double precision float uses %ld bytes\\n\", sizeof(double));\n  return 0;\n}\nOn my macbook pro laptop this results in this output:\na single precision float uses 4 bytes\na double precision float uses 8 bytes\nAccording to the IEEE 754 standard, a single precision 32-bit binary floating point representation is composed of a 1-bit sign bit (signifying whether the number is positive or negative), an 8-bit exponent and a 23-bit significand. See the various wikipedia pages for full details.\n\nFloating point error\nThere is a key phrase in the description of floating point values above, which is that floating point representation allows us to store an approximation of a real number. If we attempt to represent a number that has more significant digits than can be store in a 32-bit floating point value, then we have to approximate that real number, typically by rounding off the digits that cannot fit in the 32 bits. This introduces rounding error.\nNow with 32 bits, or even 64-bits in the case of double precision floating point values, rounding error is likely to be relatively small. However it’s not zero, and depending on what your program is doing with these values, the rounding errors can accumulate (for example if you’re simulating a dynamical system over thousands of time steps, and at each time step there is a small rounding error).\nWe don’t need a fancy simulation however to see the results of floating point rounding error. Open up your favourite programming language (MATLAB, Python, R, C, etc) and type the following (adjust the syntax as needed for your language of choice):\n\n(0.1 + 0.2) == 0.3\n\nFalse\n\n\nHow could this return False when it ought to be true?\nWhat’s going on here? What’s happening is that these decimal numbers, 0.1, 0.2 and 0.3 are being represented by the computer in a binary floating-point format, that is, using a base 2 representation. The issue is that in base 2, the decimal number 0.1 cannot be represented precisely, no matter how many bits you use. Plug in the decimal number 0.1 into an online binary/decimal/hexadecimal converter (such as here) and you will see that the binary representation of 0.1 is an infinitely repeating sequence:\n0.000110011001100110011001100... (base 2)\nThis shouldn’t be an unfamiliar situation, if we remember that there are also real numbers that cannot be represented precisely in decimal format, either, because they involve an infintely repeating sequence. For example the real number \\frac{1}{3} when represented in decimal is:\n0.3333333333... (base 10)\nIf we try to represent \\frac{1}{3} using n decimal digits then we have to chop off the digits to the right that we cannot include, thereby rounding the number. We lose some amount of precision that depends on how many significant digits we retain in our representation.\nSo the same is true in binary. There are some real numbers that cannot be represented precisely in binary floating-point format.\nSee here for some examples of significant adverse events (i.e. disasters) cause by numerical errors.\nRounding can be used to your advantage, if you’re in the business of stealing from people (see salami slicing). In the 1980s movie Superman III, Richard Pryor’s character plays a “bumbling computer genius” who embezzles a ton of money by stealing a large number of fractions of cents (which in the movie are said to be lost anyway due to rounding) from his company’s payroll (YouTube clip here).\nThere is a comprehensive theoretical summary of these issues here: What Every Computer Scientist Should Know About Floating-Point Arithmetic.\nHere is a fantastic blog post that takes you through how floating-point numbers are represented:\nExposing Floating Point\nFinally here is a recent post by Julia Evans in which she discusses different Examples of floating point problems\nand another post by Julia Evans in which she goes through the actual floating-point arithmetic that underlies the 0.1 + 0.2 == 0.3 problem: Why does 0.1 + 0.2 = 0.30000000000000004?"
  },
  {
    "objectID": "digital_representation_of_data.html#integer-overflow",
    "href": "digital_representation_of_data.html#integer-overflow",
    "title": "Digital Representation of Data",
    "section": "Integer Overflow",
    "text": "Integer Overflow\nJust in case you thought that floating point values are the only source of problems, representing integer values also comes with the problem of integer overflow. This is when one attempts to represent an integer that is larger than possible given the number of bits available.\nSo for example if we were representing positive integers using only 16 bits, we would only be able to store 2^{16}=65536 distinct values. So if the first value is 0 then we are able to store positive integers up to 65535. If we attempt to add the value 1 to a variable that uses 16 bits and is currently storing the value 65535, the variable will “overflow”, probably back to zero, in this case.\nHere is a not-well-enough-known recent case of integer overflow error affecting Boeing’s new 787 “Dreamliner” aircraft:\nReboot Your Dreamliner Every 248 Days To Avoid Integer Overflow"
  },
  {
    "objectID": "digital_representation_of_data.html#floating-point-precision",
    "href": "digital_representation_of_data.html#floating-point-precision",
    "title": "Digital Representation of Data",
    "section": "Floating point precision",
    "text": "Floating point precision\nOne non-intuitive feature of floating point representations is that the precision varies with the magnitude of the number being represented. That is, the “next possible representable number” is a very small step away from the current number, when the number is relatively small… but it becomes very large indeed when the numbers are large, sitting far along the number line.\nIn Python the numpy package has a function called nextafter() that will report the next representable value from a given value towards a second value:\n\nimport numpy as np\nx = 1.234\nx2 = np.nextafter(x, +np.inf)\nprint(f\"smallest possible increment after {x} is\\n {x2-x:0.20f}\")\n\nsmallest possible increment after 1.234 is\n 0.00000000000000022204\n\n\nNow let’s try this with a larger number:\n\nimport numpy as np\nx = 1234567890.123\nx2 = np.nextafter(x, +np.inf)\nprint(f\"smallest possible increment after {x} is\\n {x2-x:0.20f}\")\n\nsmallest possible increment after 1234567890.123 is\n 0.00000023841857910156\n\n\nNow let’s try a much larger number:\n\nimport numpy as np\nx = 1.234 * 10**25\nx2 = np.nextafter(x, +np.inf)\nprint(f\"smallest possible increment after {x} is\\n {x2-x:0.1f}\")\n\nsmallest possible increment after 1.2340000000000001e+25 is\n 2147483648.0\n\n\nSo if x is 1.234 * 10**25 (admittedly a large number) then the next number that is possible to represent with floating point arithmetic is more than two billion! That’s a big “step” along the number line.\nThis is a consequence of the floating-point representation of numbers. If you are regularly dealing with very large numbers then you should be aware of this."
  },
  {
    "objectID": "digital_representation_of_data.html#size-of-python-built-in-types",
    "href": "digital_representation_of_data.html#size-of-python-built-in-types",
    "title": "Digital Representation of Data",
    "section": "Size of Python built-in types",
    "text": "Size of Python built-in types\nIn Python we can query the size (in bytes) of a given variable using the function getsizeof() which is part of the sys module:\n\nimport sys\n\na = int(12)\nprint(f\"the {type(a)} {a} uses {sys.getsizeof(a)} bytes\")\n\nb = 123.456\nprint(f\"the {type(b)} {b} uses {sys.getsizeof(b)} bytes\")\n\nthe &lt;class 'int'&gt; 12 uses 28 bytes\nthe &lt;class 'float'&gt; 123.456 uses 24 bytes\n\n\nIn Python (version 3 and above) integer variables start off using a certain number of bytes but if necessary they will expand.\n\na = 1234567890987654321234567891\nprint(f\"the {type(a)} {a} uses {sys.getsizeof(a)} bytes\")\n\nb = a * 10\nprint(f\"the {type(b)} {b} uses {sys.getsizeof(b)} bytes\")\n\nthe &lt;class 'int'&gt; 1234567890987654321234567891 uses 36 bytes\nthe &lt;class 'int'&gt; 12345678909876543212345678910 uses 40 bytes\n\n\nOf course there are limits governed for integers by the size of your system’s memory.\nIn the case of floating-point values, the limit of 64 bits for the IEEE double-precision floating point format:\n\nprint(sys.float_info.max)\n\n1.7976931348623157e+308"
  },
  {
    "objectID": "digital_representation_of_data.html#ascii",
    "href": "digital_representation_of_data.html#ascii",
    "title": "Digital Representation of Data",
    "section": "ASCII",
    "text": "ASCII\nASCII stands for American Standard Code for Information Interchange. ASCII codes delineate how text is represented in digital format for computers (as well as other communications equipment).\nASCII uses a 7-bit binary code to represent 128 specific characters of text. The first 32 codes (decimal 0 through 31) are non-printable codes like TAB, BEL (play a bell sound), CR (carriage return), etc. Decimal codes 32 through 47 are more typical text symbols like # and &. Decimal codes 48 through 57 are the numbers 0 through 9:\n\n\nCode\nprint(\"Dec Hex Oct Chr\")\nprint(\"--- --- --- ---\")\nfor n in range(48,58,1):\n    print(f\"{n:3d}  {n:x}  {n:o}   {chr(n)}\")\n\n\nDec Hex Oct Chr\n--- --- --- ---\n 48  30  60   0\n 49  31  61   1\n 50  32  62   2\n 51  33  63   3\n 52  34  64   4\n 53  35  65   5\n 54  36  66   6\n 55  37  67   7\n 56  38  70   8\n 57  39  71   9\n\n\nDecimal codes 65 through 90 are capital letters A through Z, and codes 97 through 122 are lowercase letters a through z:\n\n\nCode\nprint(\"Dec Hex Oct Chr      Dec Hex Oct Chr\")\nprint(\"--- --- --- ---      --- --- --- ---\")\nfor n in range(65,91,1):\n    print(f\"{n:3d}  {n:x} {n:o}   {chr(n)}      {n+32:3d}  {n+32:x} {n+32:o}   {chr(n+32)}\")\n\n\nDec Hex Oct Chr      Dec Hex Oct Chr\n--- --- --- ---      --- --- --- ---\n 65  41 101   A       97  61 141   a\n 66  42 102   B       98  62 142   b\n 67  43 103   C       99  63 143   c\n 68  44 104   D      100  64 144   d\n 69  45 105   E      101  65 145   e\n 70  46 106   F      102  66 146   f\n 71  47 107   G      103  67 147   g\n 72  48 110   H      104  68 150   h\n 73  49 111   I      105  69 151   i\n 74  4a 112   J      106  6a 152   j\n 75  4b 113   K      107  6b 153   k\n 76  4c 114   L      108  6c 154   l\n 77  4d 115   M      109  6d 155   m\n 78  4e 116   N      110  6e 156   n\n 79  4f 117   O      111  6f 157   o\n 80  50 120   P      112  70 160   p\n 81  51 121   Q      113  71 161   q\n 82  52 122   R      114  72 162   r\n 83  53 123   S      115  73 163   s\n 84  54 124   T      116  74 164   t\n 85  55 125   U      117  75 165   u\n 86  56 126   V      118  76 166   v\n 87  57 127   W      119  77 167   w\n 88  58 130   X      120  78 170   x\n 89  59 131   Y      121  79 171   y\n 90  5a 132   Z      122  7a 172   z\n\n\nFor a full description of the 7-bit ascii codes in their entirety, including the extended ASCII codes (where you will find things like ö and é), see this webpage:\nhttp://www.asciitable.com (ASCII Table and Extended ASCII Codes).\nIn Python you can find the ASCII integer value of a character using the ord() function. You can get the character value of an ASCII code using the chr() function.\n\nord('A')\n\n65\n\n\n\nchr(65)\n\n'A'\n\n\nYou can use your knowledge of ASCII codes to do clever things, like convert to and from uppercase and lowercase, given your knowledge that the difference (in decimal) between ASCII A and ASCII a is 32 (see the ASCII table above):\n\nchr(ord('A')+32)\n\n'a'\n\n\n\nchr(ord('a')-32)\n\n'A'\n\n\nOf course in Python there are more straightforward ways to convert between upper and lower case:\n\n'a'.upper()\n\n'A'\n\n\n\n'A'.lower()\n\n'a'"
  },
  {
    "objectID": "digital_representation_of_data.html#unicode",
    "href": "digital_representation_of_data.html#unicode",
    "title": "Digital Representation of Data",
    "section": "Unicode",
    "text": "Unicode\nThe ASCII codes only represent a limited number of characters that are useful mostly in the English language. Starting in the 1980s, Xerox, Apple, and others began work on a new variable-length encoding scheme that could represent a much larger number of characters that would be useful for the world’s languages (and now even for emoji). This is called Unicode and includes the most common standard on the web, UTF-8, which can encode more than a million different characters and symbols.\nHere is a website where you can view and search the Unicode character table.\nFor example, in Unicode the smiling face emoji 😀 is encoded using hexadecimal value 1F600:\n\nprint(f\"Unicode (hex) 1f600 is {chr(0x1f600)}\")\n\nUnicode (hex) 1f600 is 😀"
  },
  {
    "objectID": "fundamentals.html",
    "href": "fundamentals.html",
    "title": "Fundamentals",
    "section": "",
    "text": "Digital representation of data\nControl flow & Complex data types\nFunctions, File input & output"
  },
  {
    "objectID": "fundamentals.html#pauls-notes",
    "href": "fundamentals.html#pauls-notes",
    "title": "Fundamentals",
    "section": "",
    "text": "Digital representation of data\nControl flow & Complex data types\nFunctions, File input & output"
  },
  {
    "objectID": "fundamentals.html#python-fundamentals",
    "href": "fundamentals.html#python-fundamentals",
    "title": "Fundamentals",
    "section": "Python Fundamentals",
    "text": "Python Fundamentals\n\nLearning with Python 3 chapter 1: The way of the program\nLearning with Python 3 chapter 2: Variables, expressions and statements\nPython for Data Analysis chapter 1: Preliminaries\nPython for Data Analysis chapter 2: Python Language Basics, iPython, and Jupyter Notebooks\nNumPy: the absolute basics for beginners\nPython for Data Analysis chapter 4: NumPy Basics: Arrays and Vectorized Computation\na fun coding challenge: Advent of Code 2015, Day 6 (hint: use a 1000x1000 2D array)\n\n\nother useful readings\n\nThe way of the program\nVariables, expressions, and statements\nPython Language Basics\nFiles & the File System by Kieran Healy\nHow to Name Files video by Jenny Bryan\n\n\n\nConditionals, Iteration, & Control Flow\n\nLearning with Python 3 chapter 5: Conditionals\nLearning with Python 3 chapter 7: Iteration\nPython for Data Analysis chapter 3: Built-in Data Structures, Functions, and Files\nPython for Data Analysis chapter 4: NumPy Basics: Arrays and Vectorized Computation\nPython for Data Analysis chapter 5: Getting Started with pandas\nConditionals and recursion (you can ignore for now the section on recursion)\nControl Flow\n\n\n\nFile i/o\n\nNumPy reading & writing files\nNumPy data types\npandas IO tools\nPython reading and writing files\nPython for Data Analysis chapter 6: Data Loading, Storage, and File Formats\nProject Structure, file naming, folders, etc… by Danielle Navarro"
  },
  {
    "objectID": "graphics.html",
    "href": "graphics.html",
    "title": "Graphics & Figures",
    "section": "",
    "text": "Read Chapter 9, Plotting and Visualization of Python for Data Analysis by Wes McKinney, for a great introduction to the kinds of plots you can make, and a basic subset of plotting commands. It’s a great place to start.\nPython has several libraries that can be used for generating graphics. The most popular ones are matplotlib and seaborn.\n\nMatplotlib: tutorials\nThe Python Graph Gallery\nSeaborn: statistical data visualization\n\nMatplotlib is more or less a copy of MATLAB’s plotting capabilities, so if you are familiar with MATLAB, you will feel at home with matplotlib.\nSeaborn is a high-level interface for drawing attractive and informative statistical graphics. It’s a little bit like ggplot2 in R. It’s great for plotting data that’s in a tabular format."
  },
  {
    "objectID": "hw/hw01.html",
    "href": "hw/hw01.html",
    "title": "Homework 1",
    "section": "",
    "text": "Due: Jan 18 by 11:59 pm eastern standard time\nSubmit a single file called name_01.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_01.py\n\nWrite some code to complete the Parabolic Flight coding exercise. Make sure it produces the correct output given the example inputs, including the same number of decimal places."
  },
  {
    "objectID": "hw/hw03.html",
    "href": "hw/hw03.html",
    "title": "Homework 3",
    "section": "",
    "text": "Due: Feb 1 by 11:59 pm eastern standard time\nSubmit a single file called name_03.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_03.py\n\nWrite a Python program to complete the Square Digit Chains exercise.\nHint: the answer is a 7 digit number starting with 8 and ending in 6 … and if you add all the digits up you get 33."
  },
  {
    "objectID": "hw/hw05.html",
    "href": "hw/hw05.html",
    "title": "Homework 5",
    "section": "",
    "text": "Due: Feb 15 by 11:59 pm eastern standard time\nSubmit a single file called name_05.py to Brightspace/OWL where name is replaced with your last name, e.g. gribble_05.py\n\nWrite a Python program to complete the XOR Decryption exercise.\nHint: the plaintext message contains the words the, and, and that"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scientific Computing FW25 (Jan-Apr 2026)",
    "section": "",
    "text": "URL\n\n\nwww.gribblelab.org/9040\n\n\n\n\nInstructor\n\n\nPaul Gribble (pgribble at uwo dot ca)\n\n\n\n\nClasses\n\n\nMondays & Thursdays, 9:30 am - 11:00 am in WIRB 1110\n\n\n\n\nTA\n\n\nAnthony Cruz (acruz27 at uwo dot ca)"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Scientific Computing FW25 (Jan-Apr 2026)",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\nDate\nTopic / Notes\nHomework\n\n\n\n\nJan 5/8\nIntro ; Setup ; Git ; uv\n-\n\n\nJan 12/15\nFundamentals (expressions & variables)\nHW01\n\n\nJan 19/22\nFundamentals (loops & conditionals)\nHW02\n\n\nJan 26/29\nFundamentals (data structures & functions)\nHW03\n\n\nFeb 2/5\nFundamentals (NumPy & File i/o)\nHW04\n\n\nFeb 9/12\nObject Oriented Programming (OOP)\nHW05\n\n\nFeb 16/19\nno classes (reading week)\n-\n\n\nFeb 23/26\nGraphical Displays of Data\nHW06\n\n\nMar 2/5\nReproducibility/Replicability I: plaintext authoring\nHW07\n\n\nMar 9/12\nno classes (Paul away) Reproducibility/Replicability II: clean code\n-\n\n\nMar 16/19\nSampling, Signal Processing, & Filtering Data\nHW08\n\n\nMar 23/26\nStatistical Thinking & Inferential Statistical Tests\nHW09\n\n\nMar 30/Apr 2\nFitting Models to Data\nHW10\n\n\nApr 6/Apr 9\nSimulating Dynamical Systems\n-\n\n\n\n\n\n\nconcepts covered each week\nsample code produced in class"
  },
  {
    "objectID": "index.html#readings",
    "href": "index.html#readings",
    "title": "Scientific Computing FW25 (Jan-Apr 2026)",
    "section": "Readings",
    "text": "Readings\n\nPython for Data Analysis by Wes McKinney\nThe Curious Coder’s Guide to Git by Matthew Brett\nBetter Code, Better Science by Russ Poldrack"
  },
  {
    "objectID": "oop.html",
    "href": "oop.html",
    "title": "Object Oriented Programming (OOP)",
    "section": "",
    "text": "So far in this course, we’ve been writing code as a sequence of instructions — define a variable, call a function, loop over a list. This style works great for small tasks, but as programs grow, it sometimes helps to organize code around objects: bundles of related data and behavior that model things in the world. These could be experimental participants, they could be datasets of specific types (EEG dataset, or fMRI dataset), they could be computational models (recurrent neural networks) or they could be statistical models (data + parameter estimates). It is not always better to use OOP but when it is, it’s often a lot better.\nObject-Oriented Programming (OOP) lets us define our own types (called classes) that combine:\n\nAttributes — the data an object holds (e.g., a circle’s radius)\nMethods — the functions an object can perform (e.g., calculating area)\n\nThink of a class as a blueprint and an object as a specific instance built from that blueprint. A class Circle describes what circles are; a particular circle with radius 5 is an instance of that class."
  },
  {
    "objectID": "oop.html#what-is-object-oriented-programming",
    "href": "oop.html#what-is-object-oriented-programming",
    "title": "Object Oriented Programming (OOP)",
    "section": "",
    "text": "So far in this course, we’ve been writing code as a sequence of instructions — define a variable, call a function, loop over a list. This style works great for small tasks, but as programs grow, it sometimes helps to organize code around objects: bundles of related data and behavior that model things in the world. These could be experimental participants, they could be datasets of specific types (EEG dataset, or fMRI dataset), they could be computational models (recurrent neural networks) or they could be statistical models (data + parameter estimates). It is not always better to use OOP but when it is, it’s often a lot better.\nObject-Oriented Programming (OOP) lets us define our own types (called classes) that combine:\n\nAttributes — the data an object holds (e.g., a circle’s radius)\nMethods — the functions an object can perform (e.g., calculating area)\n\nThink of a class as a blueprint and an object as a specific instance built from that blueprint. A class Circle describes what circles are; a particular circle with radius 5 is an instance of that class."
  },
  {
    "objectID": "oop.html#our-first-class-circle",
    "href": "oop.html#our-first-class-circle",
    "title": "Object Oriented Programming (OOP)",
    "section": "Our First Class: Circle",
    "text": "Our First Class: Circle\nimport math\n\nclass Circle:\n    \"\"\"A circle defined by its radius.\"\"\"\n\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return math.pi * self.radius ** 2\n\n    def perimeter(self):\n        return 2 * math.pi * self.radius\nLet’s unpack this piece by piece.\n\nThe __init__ Method (The Initializer)\n__init__ is a special method that Python calls automatically when you create a new object. Its job is to set up the object’s initial state by assigning attributes.\ndef __init__(self, radius):\n    self.radius = radius\n\nself refers to the specific object being created. Every method in a class receives self as its first argument — it’s how the object refers to itself.\nself.radius = radius stores the value you pass in as an attribute on the object.\n\nCreating an instance looks like a function call:\nc = Circle(5)\nprint(c.radius)  # 5\n\n\nAttributes\nAttributes are variables that belong to an object. You access them with dot notation:\nc = Circle(3)\nprint(c.radius)       # 3\nc.radius = 10         # you can change attributes too\nprint(c.radius)       # 10\n\n\nMethods\nMethods are functions defined inside a class. They always take self as the first parameter, which gives them access to the object’s attributes.\nc = Circle(5)\nprint(c.area())       # 78.539...\nprint(c.perimeter())  # 31.415...\nNotice that when you call a method, you don’t pass self — Python handles that for you."
  },
  {
    "objectID": "oop.html#built-in-special-methods",
    "href": "oop.html#built-in-special-methods",
    "title": "Object Oriented Programming (OOP)",
    "section": "Built-in Special Methods",
    "text": "Built-in Special Methods\nPython has a set of “magic” or “dunder” (double-underscore) methods that let your objects work with built-in Python features like print(), ==, &lt;, and more.\n\n__str__ — Human-Readable Display\n__str__ controls what print() shows:\nclass Circle:\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return math.pi * self.radius ** 2\n\n    def perimeter(self):\n        return 2 * math.pi * self.radius\n\n    def __str__(self):\n        return f\"Circle(radius={self.radius})\"\nc = Circle(5)\nprint(c)  # Circle(radius=5)\nWithout __str__, printing an object gives you something unhelpful like &lt;__main__.Circle object at 0x7f3b...&gt;.\n\n\n__repr__ — Developer-Friendly Display\n__repr__ is meant to give an unambiguous representation, often one you could paste back into Python to recreate the object. It’s what you see when you type a variable name in the interactive console:\ndef __repr__(self):\n    return f\"Circle({self.radius})\"\nc = Circle(5)\nc          # In a notebook or REPL, this shows: Circle(5)\nprint(c)   # This still uses __str__:       Circle(radius=5)\n\nRule of thumb: __str__ is for users, __repr__ is for developers. If you only define one, define __repr__ — Python will fall back to it when __str__ is missing."
  },
  {
    "objectID": "oop.html#comparison-operators",
    "href": "oop.html#comparison-operators",
    "title": "Object Oriented Programming (OOP)",
    "section": "Comparison Operators",
    "text": "Comparison Operators\nWhat if we want to compare two circles? We can define what &lt;, &gt;, and == mean for our class. A natural choice is to compare by area.\nclass Circle:\n    def __init__(self, radius):\n        self.radius = radius\n\n    def area(self):\n        return math.pi * self.radius ** 2\n\n    def perimeter(self):\n        return 2 * math.pi * self.radius\n\n    def __str__(self):\n        return f\"Circle(radius={self.radius})\"\n\n    def __repr__(self):\n        return f\"Circle({self.radius})\"\n\n    def __eq__(self, other):\n        return self.area() == other.area()\n\n    def __lt__(self, other):\n        return self.area() &lt; other.area()\n\n    def __gt__(self, other):\n        return self.area() &gt; other.area()\nsmall = Circle(2)\nbig = Circle(7)\n\nprint(small == big)   # False\nprint(small &lt; big)    # True\nprint(small &gt; big)    # False\nA bonus: once you define __lt__, you can use sorted() on a list of circles!\ncircles = [Circle(5), Circle(1), Circle(3)]\nsorted_circles = sorted(circles)\nprint(sorted_circles)  # [Circle(1), Circle(3), Circle(5)]"
  },
  {
    "objectID": "oop.html#inheritance-building-on-existing-classes",
    "href": "oop.html#inheritance-building-on-existing-classes",
    "title": "Object Oriented Programming (OOP)",
    "section": "Inheritance: Building on Existing Classes",
    "text": "Inheritance: Building on Existing Classes\nInheritance lets you create a new class based on an existing one. The new class (the child or subclass) inherits all the attributes and methods of the original (the parent or superclass), and can add or change behavior.\nLet’s create a base class Shape and build specific shapes from it.\nclass Shape:\n    \"\"\"Base class for all shapes.\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n\n    def area(self):\n        raise NotImplementedError(\"Subclasses must implement area()\")\n\n    def perimeter(self):\n        raise NotImplementedError(\"Subclasses must implement perimeter()\")\n\n    def __str__(self):\n        return f\"{self.name} with area {self.area():.2f}\"\n\n    def __repr__(self):\n        return f\"{self.name}()\"\n\n    def __eq__(self, other):\n        return self.area() == other.area()\n\n    def __lt__(self, other):\n        return self.area() &lt; other.area()\n\n    def __gt__(self, other):\n        return self.area() &gt; other.area()\nA few things to notice:\n\nShape is not meant to be used directly — it’s a template. Calling area() on a plain Shape raises an error on purpose, reminding us that each specific shape must provide its own version.\nThe comparison methods and __str__ are defined here once and inherited by all subclasses, so we don’t have to rewrite them.\n\n\nDefining Subclasses\nA subclass is defined by putting the parent class name in parentheses:\nclass Circle(Shape):\n    def __init__(self, name, radius):\n        super().__init__(name)  # call the parent's __init__\n        self.radius = radius\n\n    def area(self):\n        return math.pi * self.radius ** 2\n\n    def perimeter(self):\n        return 2 * math.pi * self.radius\n\n    def __repr__(self):\n        return f\"Circle('{self.name}', radius={self.radius})\"\n\n\nclass Square(Shape):\n    def __init__(self, name, side):\n        super().__init__(name)\n        self.side = side\n\n    def area(self):\n        return self.side ** 2\n\n    def perimeter(self):\n        return 4 * self.side\n\n    def __repr__(self):\n        return f\"Square('{self.name}', side={self.side})\"\n\n\nclass Rectangle(Shape):\n    def __init__(self, name, width, height):\n        super().__init__(name)\n        self.width = width\n        self.height = height\n\n    def area(self):\n        return self.width * self.height\n\n    def perimeter(self):\n        return 2 * (self.width + self.height)\n\n    def __repr__(self):\n        return f\"Rectangle('{self.name}', width={self.width}, height={self.height})\"\n\n\nsuper() — Calling the Parent\nsuper().__init__(name) calls the Shape.__init__ method, which sets self.name. This way we reuse the parent’s setup logic instead of duplicating it. Now each shape can have a descriptive name: Circle(\"pizza\", 10.5) or Square(\"window\", 3).\n\n\nOverriding Methods\nWhen a subclass defines a method that already exists in the parent, the subclass version overrides it. Each shape above overrides area(), perimeter(), and __repr__() to provide its own behavior, while __str__, __eq__, __lt__, and __gt__ are inherited as-is from Shape."
  },
  {
    "objectID": "oop.html#polymorphism-same-interface-different-behavior",
    "href": "oop.html#polymorphism-same-interface-different-behavior",
    "title": "Object Oriented Programming (OOP)",
    "section": "Polymorphism: Same Interface, Different Behavior",
    "text": "Polymorphism: Same Interface, Different Behavior\nPolymorphism means “many forms.” Because every shape implements area() and perimeter(), we can write code that works with any shape without knowing which specific type it is:\nshapes = [Circle(\"pizza\", 5), Square(\"window\", 4), Rectangle(\"desk\", 3, 6)]\n\nfor shape in shapes:\n    print(f\"{shape.name}: area = {shape.area():.2f}, perimeter = {shape.perimeter():.2f}\")\nOutput:\npizza: area = 78.54, perimeter = 31.42\nwindow: area = 16.00, perimeter = 16.00\ndesk: area = 18.00, perimeter = 18.00\nThe loop doesn’t care whether it’s dealing with a circle, square, or rectangle. It just calls .area() and .perimeter(), and each object responds with its own version. That’s polymorphism.\nWe can also compare shapes of completely different types, because comparison is based on area:\nc = Circle(\"frisbee\", 3)       # area ≈ 28.27\ns = Square(\"coaster\", 6)       # area = 36.00\nr = Rectangle(\"postcard\", 5, 4) # area = 20.00\n\nprint(c &gt; r)         # True  — circle has more area than rectangle\nprint(s &gt; c)         # True  — square has more area than circle\n\n# Sort a mixed list of shapes by area\nall_shapes = [s, c, r]\nprint(sorted(all_shapes))\n# [Rectangle('postcard', width=5, height=4), Circle('frisbee', radius=3), Square('coaster', side=6)]"
  },
  {
    "objectID": "oop.html#putting-it-all-together",
    "href": "oop.html#putting-it-all-together",
    "title": "Object Oriented Programming (OOP)",
    "section": "Putting It All Together",
    "text": "Putting It All Together\nHere’s the complete code in one block for reference:\nimport math\n\n\nclass Shape:\n    \"\"\"Base class for all shapes.\"\"\"\n\n    def __init__(self, name):\n        self.name = name\n\n    def area(self):\n        raise NotImplementedError(\"Subclasses must implement area()\")\n\n    def perimeter(self):\n        raise NotImplementedError(\"Subclasses must implement perimeter()\")\n\n    def __str__(self):\n        return f\"{self.name} with area {self.area():.2f}\"\n\n    def __repr__(self):\n        return f\"{self.name}()\"\n\n    def __eq__(self, other):\n        return self.area() == other.area()\n\n    def __lt__(self, other):\n        return self.area() &lt; other.area()\n\n    def __gt__(self, other):\n        return self.area() &gt; other.area()\n\n\nclass Circle(Shape):\n    def __init__(self, name, radius):\n        super().__init__(name)\n        self.radius = radius\n\n    def area(self):\n        return math.pi * self.radius ** 2\n\n    def perimeter(self):\n        return 2 * math.pi * self.radius\n\n    def __repr__(self):\n        return f\"Circle('{self.name}', radius={self.radius})\"\n\n\nclass Square(Shape):\n    def __init__(self, name, side):\n        super().__init__(name)\n        self.side = side\n\n    def area(self):\n        return self.side ** 2\n\n    def perimeter(self):\n        return 4 * self.side\n\n    def __repr__(self):\n        return f\"Square('{self.name}', side={self.side})\"\n\n\nclass Rectangle(Shape):\n    def __init__(self, name, width, height):\n        super().__init__(name)\n        self.width = width\n        self.height = height\n\n    def area(self):\n        return self.width * self.height\n\n    def perimeter(self):\n        return 2 * (self.width + self.height)\n\n    def __repr__(self):\n        return f\"Rectangle('{self.name}', width={self.width}, height={self.height})\"\n\n\n# --- Demo ---\nshapes = [Circle(\"pizza\", 5), Square(\"window\", 4), Rectangle(\"desk\", 3, 6)]\n\nfor shape in shapes:\n    print(shape)\n\nprint()\nprint(\"Sorted by area:\")\nfor shape in sorted(shapes):\n    print(f\"{repr(shape):&gt;36s}  -&gt;  area = {shape.area():.2f}\")\nOutput:\npizza with area 78.54\nwindow with area 16.00\ndesk with area 18.00\n\nSorted by area:\n            Square('window', side=4)  -&gt;  area = 16.00\nRectangle('desk', width=3, height=6)  -&gt;  area = 18.00\n           Circle('pizza', radius=5)  -&gt;  area = 78.54"
  },
  {
    "objectID": "oop.html#quick-reference",
    "href": "oop.html#quick-reference",
    "title": "Object Oriented Programming (OOP)",
    "section": "Quick Reference",
    "text": "Quick Reference\n\n\n\n\n\n\n\n\nConcept\nWhat It Means\nWhere We Saw It\n\n\n\n\nClass\nA blueprint for creating objects\nclass Shape:\n\n\nInstance\nA specific object created from a class\nc = Circle(\"pizza\", 5)\n\n\nAttribute\nData stored on an object\nself.radius\n\n\nMethod\nA function that belongs to an object\ndef area(self):\n\n\n__init__\nSets up a new object’s initial state\ndef __init__(self, name, radius):\n\n\n__str__\nControls what print() displays\n\"pizza with area 78.54\"\n\n\n__repr__\nDeveloper-friendly representation\n\"Circle('pizza', radius=5)\"\n\n\n__eq__, __lt__, __gt__\nDefine ==, &lt;, &gt; for your objects\nComparing shapes by area\n\n\nInheritance\nA child class reuses a parent’s code\nclass Circle(Shape):\n\n\nsuper()\nCalls a method from the parent class\nsuper().__init__(name)\n\n\nOverriding\nA child replaces a parent’s method\nEach shape defines its own area()\n\n\nPolymorphism\nSame method name, different behavior per type\nLooping over mixed shapes"
  },
  {
    "objectID": "oop.html#resources-on-oop",
    "href": "oop.html#resources-on-oop",
    "title": "Object Oriented Programming (OOP)",
    "section": "Resources on OOP",
    "text": "Resources on OOP\n\nCS50P (Harvard online course)\n\nnotes\nvideo\n\nClasses and Objects — the Basics\nClasses and Objects — Digging a little deeper"
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set Up Your Computer",
    "section": "",
    "text": "Yes.\nSort of.\nFor this course, we will be working extensively with the command line and VS Code, which function similarly across all three major operating system, so you can use whichever OS you prefer or already have. Linux is the gold standard in scientific computing environments; most computing clusters, cloud servers, and neuroimaging pipelines run on it, so familiarity with its command line is invaluable. MacOS runs on a Unix variant under the hood, meaning the terminal experience is nearly identical, making it a convenient choice for researchers who want a polished laptop environment that translates well to work on Linux/Unix environments such as servers and clusters.\nWindows has historically been the odd one out for scientific computing, but the Windows Subsystem for Linux (WSL) has changed this dramatically. The WSL lets you run a full Linux environment inside Windows, giving you access to the same tools and workflows. For our purposes, the key is having a working terminal and Python environment.\nSo if you are already using Unix/Linux, good news, you are all set, just some configuration things and some package installs and your computing environment will be ready for a modern course in coding / scientific computing.\nIf you are using MacOS, also good news, you may not know it but MacOS is based on a Unix variant, so with some small configuration things and some package installs, you will also be ready.\nIf you are using Windows, it will be ok. Something we will cover in this course is learning to use the terminal, learning about file systems, files, directories, and so on. On Linux/Unix and on MacOS (which is based on Unix) this is straightforward and you won’t need to do anything particularly special. On Windows however you will need to do some initial setup to install something called the Windows Subsystem for Linux (WSL). This will enable you to launch a Linux session within Windows, and follow along in the course with everyone else. It’s not such a big deal. Instructions are below.\nPS: Personally I am most familiar with MacOS and Unix/Linux. I am quite unfamiliar with Windows.\n\n\nOpen up an Ubuntu terminal and (assuming Ubuntu Linux) update the system:\nsudo apt update\nsudo apt upgrade -y\nand then install some necessary tools including git:\nsudo apt install -y build-essential git curl\nand then install the uv tool:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nclose your Terminal.\nand then download Visual Studio Code and install it.\n\n\n\nOpen up a terminal and install some necessary build tools:\nxcode-select --install\nInstall the Homebrew package manager:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nThen close the terminal and open up a new one, and install some other necessary tools including git:\nbrew install git\nThen install the uv tool:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nclose your Terminal.\nand then download Visual Studio Code and install it.\nIf you want a nicer looking Terminal than the one that ships with MacOS you can try one of these:\n\niTerm2\nghostty\n\n\n\n\nFirst update Windows, I think you can access this by going to the Start menu and typing “update” and one of the options will be a system update.\nNext, open up Powershell (again, go to the Start menu and type Powershell to access it) and type:\nwsl --install\nWhen it is done, reboot your computer.\nOpen up Powershell again and type:\nwsl.exe --install Ubuntu\nIt will eventually ask you for a default Unix user account and password.\nClose Powershell and any other junky windows that Windows may have opened.\nOpen Powershell and check to see which version of WSL is running:\nwsl -l -v\nif it shows version 1 instead of version 2 then switch:\nwsl --set-version Ubuntu 2\nClose Powershell and reboot the computer.\nFrom your Start menu select “Ubuntu” and it should launch a terminal, which is now, running Ubuntu linux.\nNow go through the steps above in the Unix/Linux section."
  },
  {
    "objectID": "setup.html#macos-windows-or-linux",
    "href": "setup.html#macos-windows-or-linux",
    "title": "Set Up Your Computer",
    "section": "",
    "text": "Yes.\nSort of.\nFor this course, we will be working extensively with the command line and VS Code, which function similarly across all three major operating system, so you can use whichever OS you prefer or already have. Linux is the gold standard in scientific computing environments; most computing clusters, cloud servers, and neuroimaging pipelines run on it, so familiarity with its command line is invaluable. MacOS runs on a Unix variant under the hood, meaning the terminal experience is nearly identical, making it a convenient choice for researchers who want a polished laptop environment that translates well to work on Linux/Unix environments such as servers and clusters.\nWindows has historically been the odd one out for scientific computing, but the Windows Subsystem for Linux (WSL) has changed this dramatically. The WSL lets you run a full Linux environment inside Windows, giving you access to the same tools and workflows. For our purposes, the key is having a working terminal and Python environment.\nSo if you are already using Unix/Linux, good news, you are all set, just some configuration things and some package installs and your computing environment will be ready for a modern course in coding / scientific computing.\nIf you are using MacOS, also good news, you may not know it but MacOS is based on a Unix variant, so with some small configuration things and some package installs, you will also be ready.\nIf you are using Windows, it will be ok. Something we will cover in this course is learning to use the terminal, learning about file systems, files, directories, and so on. On Linux/Unix and on MacOS (which is based on Unix) this is straightforward and you won’t need to do anything particularly special. On Windows however you will need to do some initial setup to install something called the Windows Subsystem for Linux (WSL). This will enable you to launch a Linux session within Windows, and follow along in the course with everyone else. It’s not such a big deal. Instructions are below.\nPS: Personally I am most familiar with MacOS and Unix/Linux. I am quite unfamiliar with Windows.\n\n\nOpen up an Ubuntu terminal and (assuming Ubuntu Linux) update the system:\nsudo apt update\nsudo apt upgrade -y\nand then install some necessary tools including git:\nsudo apt install -y build-essential git curl\nand then install the uv tool:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nclose your Terminal.\nand then download Visual Studio Code and install it.\n\n\n\nOpen up a terminal and install some necessary build tools:\nxcode-select --install\nInstall the Homebrew package manager:\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nThen close the terminal and open up a new one, and install some other necessary tools including git:\nbrew install git\nThen install the uv tool:\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nclose your Terminal.\nand then download Visual Studio Code and install it.\nIf you want a nicer looking Terminal than the one that ships with MacOS you can try one of these:\n\niTerm2\nghostty\n\n\n\n\nFirst update Windows, I think you can access this by going to the Start menu and typing “update” and one of the options will be a system update.\nNext, open up Powershell (again, go to the Start menu and type Powershell to access it) and type:\nwsl --install\nWhen it is done, reboot your computer.\nOpen up Powershell again and type:\nwsl.exe --install Ubuntu\nIt will eventually ask you for a default Unix user account and password.\nClose Powershell and any other junky windows that Windows may have opened.\nOpen Powershell and check to see which version of WSL is running:\nwsl -l -v\nif it shows version 1 instead of version 2 then switch:\nwsl --set-version Ubuntu 2\nClose Powershell and reboot the computer.\nFrom your Start menu select “Ubuntu” and it should launch a terminal, which is now, running Ubuntu linux.\nNow go through the steps above in the Unix/Linux section."
  },
  {
    "objectID": "setup.html#check-your-setup",
    "href": "setup.html#check-your-setup",
    "title": "Set Up Your Computer",
    "section": "Check your setup",
    "text": "Check your setup\nCreate a new folder somewhere on your computer’s file system and name it Psych_9040, and then navigate inside of it.\nOpen Ubuntu:\nmkdir Psych_9040\ncd Psych_9040\nUse uv to install a python environment\nuv init --python 3.12\nAdd the numpy package\nuv add numpy\nCreate a new empty file:\ntouch hello.py\nand add some Python lines of code to it:\necho \"import numpy as np\" &gt;&gt; hello.py\necho \"x = np.array ([2, 3, 5, 7, 11, 13, 17, 19, 23, 29])\" &gt;&gt; hello.py\necho \"y = np.sum(x)\" &gt;&gt; hello.py\necho \"print(f\\\"the sum of {x} is {y}\\\")\" &gt;&gt; hello.py\nand test the code:\nuv run python hello.py\nand you should see this output:\nthe sum of [ 2  3  5  7 11 13 17 19 23 29] is 129"
  },
  {
    "objectID": "setup.html#gitgithub",
    "href": "setup.html#gitgithub",
    "title": "Set Up Your Computer",
    "section": "Git/GitHub",
    "text": "Git/GitHub\nWe will be learning about and using code versioning with Git and GitHub, so you should sign up for a (free) GitHub account."
  },
  {
    "objectID": "setup.html#visual-studio-code",
    "href": "setup.html#visual-studio-code",
    "title": "Set Up Your Computer",
    "section": "Visual Studio Code",
    "text": "Visual Studio Code\nAfter installing VS Code, launch it, and enable launching from the terminal.\n\nMacOS\n\nOpen VS Code: Launch the Visual Studio Code application.\nInstall Shell Command by Open the Command Palette by pressing Shift + Command + P (or F1).\nType “shell command” into the prompt.\nSelect the command “Shell Command: Install ‘code’ command in PATH”. (You might be prompted for your administrator password.)\nLaunch from Terminal: Open your terminal. Navigate to the directory of your project. Type the following command:\n\ncode .\nThe . opens the current directory in a new VS Code window. You can replace . with a specific file name or directory path.\n\n\nWSL on Windows\n\nLaunch VS Code in your Windows environment.\nOpen the Command Palette (Ctrl + Shift + P).\nType “shell command” and select “Shell Command: Install ‘code’ command in PATH” if you didn’t do so during the initial installation of the Remote - WSL extension. The extension should typically handle this installation, but verifying doesn’t hurt.\nLaunch from WSL Terminal: Open your WSL terminal (e.g., Ubuntu). Navigate to your project directory within the Linux environment. Type the command:\n\ncode .\nThis command will open the current Linux directory in a new VS Code window on your Windows desktop, automatically connecting via the Remote - WSL extension."
  }
]